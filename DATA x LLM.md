# Data *×* LLM: From Principles to Practices

## 1. INTRODUCTION

**Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic** 

Sachin Goyal, Pratyush Maini, Zachary C. Lipton, Aditi Raghunathan, J. Zico Kolter. 

*CVPR 2024.* [[pdf](https://doi.org/10.48550/arXiv.2404.07177)] 

**When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale** 

Max Marion, Ahmet Üstün, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, Sara Hooker. 

*NeurIPS 2023.* [[pdf](https://doi.org/10.48550/arXiv.2309.04564)] 

**Data-efficient Fine-tuning for LLM - based Recommendation** 

Xinyu Lin, Wenjie Wang, Yongqi Li, Shuo Yang, Fuli Feng, Yinwei Wei, Tat - Seng Chua. 

*SIGIR 2024.* [[pdf](https://doi.org/10.48550/arXiv.2401.17197)] 

**Language Models are Unsupervised Multitask Learners** 

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. 

*OpenAI blog 2019.* [[pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)] 

**Baichuan 2: Open Large-scale Language Models** 

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, JunTao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu. 

*arXiv:2309.10305 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2309.10305)] 

**Qwen Technical Report** 

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, Tianhang Zhu. 

*arXiv:2309.16609 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2309.16609)] 



### 1.1 Data Management for LLM (DM4LLM)

**A survey of large language models**

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, Ji-Rong Wen. 

*arxiv 2023.* [[pdf](https://arxiv.org/abs/2303.18223)]

**A survey on multimodal large language models**

Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, Enhong Chen. 

*CoRR 2023.* [[pdf](https://arxiv.org/abs/2306.13549)]

**The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective**
Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2407.08583)]



### 1.2 LLM for Data Management (LLM4DM)

### 1.3 Comparison with Existing Surveys

**Data Management For Training Large Language Models: A Survey**

Zige Wang, Wanjun Zhong, Yufei Wang, Qi Zhu, Fei Mi, Baojun Wang, Lifeng Shang, Xin Jiang, Qun Liu. 

*arxiv 2023.* [[pdf](https://doi.org/10.48550/arXiv.2312.01700)]

**A Survey on Data Selection for Language Models** 

Alon Albalak, Yanai Elazar, Sang Michael Xie, Shayne Longpre, Nathan Lambert, Xinyi Wang, Niklas Muennighoff, Bairu Hou, Liangming Pan, Haewon Jeong, Colin Raffel, Shiyu Chang, Tatsunori Hashimoto, William Yang Wang. 

*arXiv:2402.16827 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2402.16827)] 

**Large Language Models for Data Annotation and Synthesis: A Survey** 

Zhen Tan, Dawei Li, Song Wang, Alimohammad Beigi, Bohan Jiang, Amrita Bhattacharjee, Mansooreh Karami, Jundong Li, Lu Cheng, Huan Liu. 

*EMNLP 2024.* [[pdf](https://doi.org/10.48550/arXiv.2402.13446)] 

**On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey** 

Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, Haobo Wang. 

*arXiv:2406.15126 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2406.15126)] 

**Big data storage technologies: a survey** 

Aisha Siddiqa, Ahmad Karim, Abdullah Gani. 

*Frontiers of Information Technology & Electronic Engineering, 2017, 18:1040–1070.* [[pdf](https://link.springer.com/article/10.1631/FITEE.1500441)] 

**Survey of vector database management systems** 

James Jie Pan, Jianguo Wang, Guoliang Li. 

*The VLDB Journal, Volume 33, Issue 5, July 15, 2024, Pages 1591 - 1615.* [[pdf](https://doi.org/10.1007/s00778-024-00864-x)] 

**Large Language Model for Table Processing: A Survey** 

Weizheng Lu, Jing Zhang, Ju Fan, Zihao Fu, Yueguo Chen, Xiaoyong Du. 

*Accepted by Frontiers of Computer Science (FCS), arXiv:2402.05121v3 [cs.AI].* [[pdf](https://arxiv.org/abs/2402.05121)] 



## 2 Data Management for LLM

### 2.1 Data Characteristics Across Different LLM Stages

**RedPajama: An Open Dataset for Training Large Language Models**  

Maurice Weber, Daniel Fu, Quentin Anthony, Yonatan Oren, Shane Adams, Anton Alexandrov, Xiaozhong Lyu, Huu Nguyen, Xiaozhe Yao, Virginia Adams, Ben Athiwaratkun, Rahul Chalamala, Kezhen Chen, Max Ryabinin, Tri Dao, Percy Liang, Christopher Ré, Irina Rish, Ce Zhang  

*NeurIPS 2024 (Datasets and Benchmarks Track)* [[pdf](https://doi.org/10.48550/arXiv.2411.12372)]

**The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale** 

Guilherme Penedo, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, Thomas Wolf. 

*NeurIPS 2024.* [[pdf](https://doi.org/10.48550/arXiv.2406.17557)] 

**MM-LLMs: Recent Advances in MultiModal Large Language Models** 

Duzhen Zhang, Yahan Yu, Jiahua Dong, Chenxing Li, Dan Su, Chenhui Chu, Dong Yu. 

*ACL 2024 (findings).* [[pdf](https://doi.org/10.48550/arXiv.2401.13601)] 

**OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents** 

Hugo Laurençon, Lucile Saulnier, Leo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander Rush, Douwe Kiela, Matthieu Cord, Victor Sanh. 

*Advances in Neural Information Processing Systems 36 (NeurIPS 2023), Datasets and Benchmarks Track.*  [[pdf](https://arxiv.org/abs/2306.16527)] 

**Advances in natural language processing** 

Julia Hirschberg, Christopher D. Manning. 

*Science, Vol 349, Issue 6245, 17 Jul 2015, pp. 261 - 266.* [[pdf](https://doi.org/10.1126/science.aaa8685)] 

**BBT - Fin: Comprehensive Construction of Chinese Financial Domain Pre - trained Language Model, Corpus and Benchmark** 

Dakuan Lu, Hengkui Wu, Jiqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin, Yanghua Xiao.

*arXiv:2302.09432v2 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2302.09432)] 

**Continual pre - training mitigates forgetting in language and vision**

Andrea Cossu, Antonio Carta, Lucia Passaro, Vincenzo Lomonaco, Tinne Tuytelaars, Davide Bacciu.

*Neural Networks, Vol. 179, No. C, November 1, 2024.* [[pdf](https://doi.org/10.1016/j.neunet.2024.106492)]

**UltraFeedback: Boosting Language Models with Scaled AI Feedback** 

Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong Xie, Ruobing Xie, Yankai Lin, Zhiyuan Liu, Maosong Sun. 

*ICML 2024.* [[pdf](https://doi.org/10.48550/arXiv.2310.01377)] 

**DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning**

DeepSeek-AI, Daya Guo, Dejian Yang, et al. 

*arXiv:2501.12948 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2501.12948)]

**DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services** 

Shengbin Yue, Wei Chen, Siyuan Wang, Bingxuan Li, Chenchen Shen, Shujun Liu, Yuxuan Zhou, Yao Xiao, Song Yun, Xuanjing Huang, Zhongyu Wei 

*arXiv:2309.11325v2 [cs.CL] .* [[pdf](https://arxiv.org/abs/2309.11325)] 

**Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval - Augmented Generation** 

Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Vicente Grau 

*arXiv:2408.04187v2 [cs.CV] .* [[pdf](https://doi.org/10.48550/arXiv.2408.04187)] 

**MMMU: A Massive Multi - discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI** 

Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen 

*arXiv:2311.16502 [cs.CL].* [[pdf](https://arxiv.org/abs/2311.16502v4)] 

**Evaluating Large Language Models Trained on Code** 

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba 

*arXiv:2107.03374 [cs.LG].* [[pdf](https://arxiv.org/abs/2107.03374v2)] 

**What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams** 

Di Jin, Eileen Pan, Nassim Oufattole, Wei - Hung Weng, Hanyi Fang, Peter Szolovits 

*arXiv:2009.13081 [cs.CL].* [[pdf](https://arxiv.org/abs/2009.13081v1)] 

**LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models** 

Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu 

*arXiv:2409.20288 [cs.CL].* [[pdf](https://arxiv.org/abs/2409.20288v4)] 



### 2.2 Data Processing for LLM

#### 2.2.1 Data Acquisition

**Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books** 

Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler 

*In 2015 IEEE International Conference on Computer Vision (ICCV), 2015, pp. 19 - 27.* [[pdf](https://doi.org/10.1109/ICCV.2015.11)] 

**The Stack: 3 TB of permissively licensed source code** 

Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Muñoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von Werra, Harm de Vries 

*arXiv:2211.15533 [cs.CL].* [[pdf](https://arxiv.org/abs/2211.15533v1)] 

**Exploring the limits of transfer learning with a unified text - to - text transformer** 

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu 

*In The Journal of Machine Learning Research, 2020, Volume 21, Issue 1, Article No.: 140, pp. 5485 - 5551.* [[pdf](https://arxiv.org/abs/1910.10683)] 

**mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer** 

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel 

*In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021, pp. 483–498, Online.* [[pdf](https://aclanthology.org/2021.naacl-main.41.pdf)]

**CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages** 

Thuat Nguyen, Chien Van Nguyen, Viet Dac Lai, Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Ryan A. Rossi, Thien Huu Nguyen 

*In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), 2024, pp. 4226–4237, Torino, Italia.* [[pdf](https://aclanthology.org/2024.lrec-main.377.pdf)]

**CodeSearchNet Challenge: Evaluating the State of Semantic Code Search**

Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, Marc Brockschmidt

*arXiv:1909.09436 [cs.LG].* [[pdf](https://arxiv.org/abs/1909.09436v3)]

**Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction** 

Adrien Barbaresi 

*In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, 2021, pp. 122 - 131.* [[pdf](https://aclanthology.org/2021.acl-demo.15.pdf)] 

**An Empirical Comparison of Web Content Extraction Algorithms** 

Janek Bevendorff, Sanket Gupta, Johannes Kiesel, Benno Stein 

*In SIGIR '23: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2023, pp. 2594 - 2603.* [[pdf](https://doi.org/10.1145/3539618.3591920)] 

**Fact or Fiction: Content Classification for Digital Libraries** 

Aidan Finn, N. Kushmerick, Barry Smyth 

*Published in DELOS Workshops / Conferences, 2001.* [[pdf](https://www.semanticscholar.org/paper/Fact-or-Fiction%3A-Content-Classification-for-Digital-Finn-Kushmerick/73ccd5c477b37a082f66557a1793852d405e4b6d)] 

**Content extraction using diverse feature sets** 

Matthew E. Peters, Dan Lecocq 

*In WWW '13 Companion: Proceedings of the 22nd International Conference on World Wide Web, 2013, pp. 89 - 90.* [[pdf](https://doi.org/10.1145/2487788.2487828)] 

**General OCR Theory: Towards OCR - 2.0 via a Unified End - to - end Model** 

Haoran Wei, Chenglong Liu, Jinyue Chen, Jia Wang, Lingyu Kong, Yanming Xu, Zheng Ge, Liang Zhao, Jianjian Sun, Yuang Peng, Chunrui Han, Xiangyu Zhang 

*arXiv:2409.01704 [cs.CV].* [[pdf](https://arxiv.org/abs/2409.01704v1)] 

**ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking** 

Tom Ayoola, Shubhi Tyagi, Joseph Fisher, Christos Christodoulopoulos, Andrea Pierleoni 

*In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track, 2022, pp. 209–220, Hybrid: Seattle, Washington + Online.* [[pdf](https://aclanthology.org/2022.naacl-industry.24.pdf)]

**WebIE: Faithful and Robust Information Extraction on the Web**
Chenxi Whitehouse, Clara Vania, Alham Fikri Aji, Christos Christodoulopoulos, Andrea Pierleoni. 

*ACL 2023.*[[pdf](https://aclanthology.org/2023.acl-long.428/)]

**Alignment-Augmented Consistent Translation for Multilingual Open Information Extraction**
Keshav Kolluru, Muqeeth Mohammed, Shubham Mittal, Soumen Chakrabarti, Mausam. 

*ACL 2022.*[[pdf](https://aclanthology.org/2022.acl-long.179/)]

**Optimizing Data Collection for Machine Learning**
Rafid Mahmood, James Lucas, Jose M. Alvarez, Sanja Fidler, Marc T. Law. 

*NeurIPS 2022.*[[pdf](https://arxiv.org/abs/2210.01234)]

**MinerU: An Open-Source Solution for Precise Document Content Extraction**
Bin Wang, Chao Xu, Xiaomeng Zhao, Linke Ouyang, Fan Wu, Zhiyuan Zhao, Rui Xu, Kaiwen Liu, Yuan Qu, Fukai Shang, Bo Zhang, Liqun Wei, Zhihao Sui, Wei Li, Botian Shi, Yu Qiao, Dahua Lin, Conghui He. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2409.18839)]

**LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking**
Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei. 

*ACM Multimedia 2022.*[[pdf](https://arxiv.org/abs/2204.08387)]

**YOLOv10: Real-Time End-to-End Object Detection**
*Ao Wang, Hui Chen, Lihao Liu, Kai Chen, Zijia Lin, Jungong Han, Guiguang Ding.*

*NeurIPS 2024*.[[pdf](https://arxiv.org/abs/2405.14458)]

**UMIE: Unified Multimodal Information Extraction with Instruction Tuning**
Lin Sun, Kai Zhang, Qingyuan Li, Renze Lou. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2401.03082)]

**Focus Anywhere for Fine-grained Multi-page Document Understanding**
Chenglong Liu, Haoran Wei, Jinyue Chen, Lingyu Kong, Zheng Ge, Zining Zhu, Liang Zhao, Jianjian Sun, Chunrui Han, Xiangyu Zhang. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2405.14295)]

**Learning Transferable Visual Models From Natural Language Supervision**
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 

*arxiv 2021.*[[pdf](https://arxiv.org/abs/2103.00020)]

**Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models**
Haoran Wei, Lingyu Kong, Jinyue Chen, Liang Zhao, Zheng Ge, Jinrong Yang, Jianjian Sun, Chunrui Han, Xiangyu Zhang. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2312.06109)]

**Tesseract: An Open-Source Optical Character Recognition Engine**

Anthony Kay

*Linux Journal, Volume 2007, Issue 159* [[pdf](https://dl.acm.org/doi/10.5555/1288165.1288167)]



#### 2.2.2 Data Deduplication

**LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs**

Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, Aran Komatsuzaki

*Data Centric AI NeurIPS Workshop 2021* [[pdf](https://doi.org/10.48550/arXiv.2111.02114)]

**Effective Pruning of Web-Scale Datasets Based on Complexity of Concept Clusters**

Amro Abbas, Evgenia Rusak, Kushal Tirumala, Wieland Brendel, Kamalika Chaudhuri, Ari S. Morcos

*ICLR 2024* [[pdf](https://doi.org/10.48550/arXiv.2401.04578)]

**Scaling Laws and Interpretability of Learning from Repeated Data**
Danny Hernandez, Tom Brown, Tom Conerly, Nova DasSarma, Dawn Drain, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Tom Henighan, Tristan Hume, Scott Johnston, Ben Mann, Chris Olah, Catherine Olsson, Dario Amodei, Nicholas Joseph, Jared Kaplan, Sam McCandlish. 

*arxiv 2022.*[[pdf](https://arxiv.org/abs/2205.10487)]

**Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models** 

Wenbei Xie 

*arXiv:2310.04039 [cs.CL].* [[pdf](https://arxiv.org/abs/2310.04039v1)] 

**Deduplicating Training Data Mitigates Privacy Risks in Language Models** 

Nikhil Kandpal, Eric Wallace, Colin Raffel 

*arXiv:2202.06539 [cs.CR].* [[pdf](https://arxiv.org/abs/2202.06539v3)] 

**BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline**
Guosheng Dong, Da Pan, Yiding Sun, Shusen Zhang, Zheng Liang, Xin Wu, Yanjun Shen, Fan Yang, Haoze Sun, Tianpeng Li, Mingan Lin, Jianhua Xu, Yufan Zhang, Xiaonan Nie, Lei Su, Bingning Wang, Wentao Zhang, Jiaxin Mao, Zenan Zhou, Weipeng Chen. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2408.15079)]

**Deduplicating Training Data Makes Language Models Better**
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, Nicholas Carlini. 

*ACL 2022.*[[pdf](https://arxiv.org/abs/2107.06499)]

**SlimPajama-DC: Understanding Data Combinations for LLM Training**
Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Zhengzhong Liu, Hongyi Wang, Bowen Tan, Joel Hestness, Natalia Vassilieva, Daria Soboleva, Eric Xing. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2309.10818)]

**LSHBloom: Memory-efficient, Extreme-scale Document Deduplication**
*Arham Khan, Robert Underwood, Carlo Siebenschuh, Yadu Babuji, Aswathy Ajith, Kyle Hippe, Ozan Gokdemir, Alexander Brace, Kyle Chard, Ian Foster.*

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2411.04257)]

**SemDeDup: Data-efficient learning at web-scale through semantic deduplication**
Amro Abbas, Kushal Tirumala, Dániel Simig, Surya Ganguli, Ari S. Morcos. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2303.09540)]

**FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication**
Eric Slyman, Stefan Lee, Scott Cohen, Kushal Kafle. 

*CVPR 2024.*[[pdf](https://arxiv.org/abs/2404.16123)]

**SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training**
Nan He, Weichen Xiong, Hanwen Liu, Yi Liao, Lei Ding, Kai Zhang, Guohua Tang, Xiao Han, Yang Wei. 

*ACL 2024.*[[pdf](https://aclanthology.org/2024.acl-long.220/)]

**Suffix arrays: a new method for on-line string searches**
Udi Manber, Gene Myers. 

*SIAM Journal on Computing, Volume 22, Issue 5, Pages 935-948, 1993.*[[pdf](https://doi.org/10.1137/0222058)]

**On the Resemblance and Containment of Documents**
A. Broder. 

*SEQUENCES '97: Proceedings of the Compression and Complexity of Sequences 1997, Page 21, 1997.*[[pdf](https://doi.org/10.1109/SEQUEN.1997.666900)]

**Noise-Robust De-Duplication at Scale**
Emily Silcock, Luca D'Amico-Wong, Jinglin Yang, Melissa Dell. 

*arxiv 2022.*[[pdf](https://arxiv.org/abs/2210.04261)]

**Similarity estimation techniques from rounding algorithms** 

Moses S. Charikar 

*In STOC '02: Proceedings of the thirty - fourth annual ACM symposium on Theory of computing, 2002, pp. 380 - 388.* [[pdf](https://doi.org/10.1145/509907.509965)] 

**Data-Juicer: A One-Stop Data Processing System for Large Language Models**
Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, Jingren Zhou. 

*SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data, Pages 120-134, 2024.*[[pdf](https://doi.org/10.1145/3626246.3653385)]

**DotHash: Estimating Set Similarity Metrics for Link Prediction and Document Deduplication** 

Igor Nunes, Mike Heddes, Pere Vergés, Danny Abraham, Alex Veidenbaum, Alex Nicolau, Tony Givargis 

*In KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2023, pp. 1758 - 1769.* [[pdf](https://doi.org/10.1145/3580305.3599314)] 

**Learning Transferable Visual Models From Natural Language Supervision**
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 

*arxiv 2021.*[[pdf](https://arxiv.org/abs/2103.00020)]

**In Defense of Minhash over Simhash**

Anshumali Shrivastava, Ping Li

*In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, 2014, PMLR 33:886 - 894.* [[pdf](https://arxiv.org/abs/1407.4416v1)]

**Noise-Robust De-Duplication at Scale** 

Emily Silcock, Luca D'Amico-Wong, Jinglin Yang, Melissa Dell 

*arXiv:2210.04261 [cs.CL].* [[pdf](https://arxiv.org/abs/2210.04261v2)] 

**OPT: Open Pre-trained Transformer Language Models** 

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer 

*arXiv:2205.01068 [cs.CL].* [[pdf](https://arxiv.org/abs/2205.01068v4)] 

**D4: Improving LLM Pretraining via Document De-Duplication and Diversification**
*Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari Morcos.*

*NeurIPS 2023.*[[pdf](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a8f8cbd7f7a5fb2c837e578c75e5b615-Abstract-Datasets_and_Benchmarks.html)]



#### 2.2.3 Data Filtering

**MoDS: Model-oriented Data Selection for Instruction Tuning**

Qianlong Du, Chengqing Zong, Jiajun Zhang

*arXiv:2311.15653 [cs.CL] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2311.15653)]

**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**

Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova

*Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019* [[pdf](https://aclanthology.org/N19-1423.pdf)]

**Active Learning for Convolutional Neural Networks: A Core-Set Approach**

Ozan Sener, Silvio Savarese

*ICLR 2018* [[pdf](https://doi.org/10.48550/arXiv.1708.00489)]

**Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach**

Yue Yu, Rongzhi Zhang, Ran Xu, Jieyu Zhang, Jiaming Shen, Chao Zhang

*ACL 2023* [[pdf](https://doi.org/10.48550/arXiv.2209.06995)]

**Effective Pruning of Web-Scale Datasets Based on Complexity of Concept Clusters**

Amro Abbas, Evgenia Rusak, Kushal Tirumala, Wieland Brendel, Kamalika Chaudhuri, Ari S. Morcos

*ICLR 2024* [[pdf](https://doi.org/10.48550/arXiv.2401.04578)]

**SemDeDup: Data-efficient learning at web-scale through semantic deduplication**
Amro Abbas, Kushal Tirumala, Dániel Simig, Surya Ganguli, Ari S. Morcos. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2303.09540)]

**Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models**

Zachary Ankner, Cody Blakeney, Kartik Sreenivasan, Max Marion, Matthew L. Leavitt, Mansheej Paul

*arXiv:2405.20541 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2405.20541)]

**NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks**

Jean-michel Attendu, Jean-philippe Corbeil

*Proceedings of The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP), 2023* [[pdf](https://aclanthology.org/2023.sustainlp-1.9/)]

**Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning**

Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning Cheng, Tianyi Zhou

*ACL 2024* [[pdf](https://doi.org/10.48550/arXiv.2402.00530)]

**When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale**
Max Marion, Ahmet Üstün, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, Sara Hooker. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2309.04564)]

**Emergent and Predictable Memorization in Large Language Models**
Stella Biderman, USVSN Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin Anthony, Shivanshu Purohit, Edward Raff. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2304.11158)]

**Data-efficient Fine-tuning for LLM-based Recommendation**
Xinyu Lin, Wenjie Wang, Yongqi Li, Shuo Yang, Fuli Feng, Yinwei Wei, Tat-Seng Chua. 

*SIGIR 2024.*[[pdf](https://arxiv.org/abs/2401.17197)]

**Data Pruning via Moving-one-Sample-out**
Haoru Tan, Sitong Wu, Fei Du, Yukang Chen, Zhibin Wang, Fan Wang, Xiaojuan Qi. 

*NeurIPS 2023.*[[pdf](https://arxiv.org/abs/2310.14664)]

**Instruction Mining: Instruction Data Selection for Tuning Large Language Models**
Yihan Cao, Yanbin Kang, Chi Wang, Lichao Sun. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2307.06290)]

**SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning**
Yexiao He, Ziyao Wang, Zheyu Shen, Guoheng Sun, Yucong Dai, Yongkai Wu, Hongyi Wang, Ang Li. 

*NeurIPS 2024.*[[pdf](https://arxiv.org/abs/2405.00705)]

**QuRating: Selecting High-Quality Data for Training Language Models**
Alexander Wettig, Aatmik Gupta, Saumya Malik, Danqi Chen. 

*ICML 2024.*[[pdf](https://arxiv.org/abs/2402.09739)]

**What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**
Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, Junxian He. 

*ICLR 2024.*[[pdf](https://arxiv.org/abs/2312.15685)]

**Biases in Large Language Models: Origins, Inventory, and Discussion**
Roberto Navigli, Simone Conia, Björn Ross. 

*ACM Journal of Data and Information Quality, Volume 15, Issue 2, Article No. 10, Pages 1-21, 2023.*[[pdf](https://doi.org/10.1145/3597307)]

**SEAL: Safety-enhanced Aligned LLM Fine-tuning via Bilevel Data Selection**
Han Shen, Pin-Yu Chen, Payel Das, Tianyi Chen. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2410.07471)]

**Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic**
Sachin Goyal, Pratyush Maini, Zachary C. Lipton, Aditi Raghunathan, J. Zico Kolter. 

*CVPR 2024.*[[pdf](https://arxiv.org/abs/2404.07177)]

**Baichuan 2: Open Large-scale Language Models**
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, JunTao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2309.10305)]

**Analyzing Leakage of Personally Identifiable Information in Language Models**
Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, Santiago Zanella-Béguelin. 

*IEEE Symposium on Security and Privacy (S&P) 2023.*[[pdf](https://arxiv.org/abs/2302.00539)]

**DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4**
Zhengliang Liu, Yue Huang, Xiaowei Yu, Lu Zhang, Zihao Wu, Chao Cao, Haixing Dai, Lin Zhao, Yiwei Li, Peng Shu, Fang Zeng, Lichao Sun, Wei Liu, Dinggang Shen, Quanzheng Li, Tianming Liu, Dajiang Zhu, Xiang Li. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2303.11032)]

**Annotating longitudinal clinical narratives for de-identification: The 2014 i2b2/UTHealth corpus**
Amber Stubbs, Özlem Uzuner. 

*Journal of Biomedical Informatics, Volume 58, Issue S, Pages S20-S29, 2015.*[[pdf](https://www.sciencedirect.com/science/article/pii/S1532046415001823)]

**FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP**
Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, Roland Vollgraf. 

*NAACL 2019.*[[pdf](https://aclanthology.org/N19-4010/)]

**Economic Hyperparameter Optimization With Blended Search Strategy** 

Chi Wang, Qingyun Wu, Silu Huang, Amin Saied 

*In Proceedings of the 9th International Conference on Learning Representations (ICLR 2021)*  [[pdf](https://iclr.cc/virtual/2021/poster/3052)] 

**LAB: Large-Scale Alignment for ChatBots**

Shivchander Sudalairaj, Abhishek Bhandwaldar, Aldo Pareja, Kai Xu, David D. Cox, Akash Srivastava

*arXiv:2403.01081 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.01081)]

**Rethinking the Instruction Quality: LIFT is What You Need**

Yang Xu, Yongqiang Yao, Yufan Huang, Mengnan Qi, Maoquan Wang, Bin Gu, Neel Sundaresan

*arXiv:2312.11508 [cs.CL] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2312.11508)]

**Entropy Law: The Story Behind Data Compression and LLM Performance**

Mingjia Yin, Chuhan Wu, Yufei Wang, Hao Wang, Wei Guo, Yasheng Wang, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen

*arXiv:2407.06645 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2407.06645)]

**G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**

Xingyuan Pan, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Shanbo Cheng

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024* [[pdf](https://aclanthology.org/2024.acl-long.821.pdf)]



#### 2.2.4 Data Transformation 

**Data-Juicer: A One-Stop Data Processing System for Large Language Models**

Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, Jingren Zhou. 

*SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data, Pages 120-134, 2024.*[[pdf](https://doi.org/10.1145/3626246.3653385)]

**UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering**
Barlas Oguz, Xilun Chen, Vladimir Karpukhin, Stan Peshterliev, Dmytro Okhonko, Michael Schlichtkrull, Sonal Gupta, Yashar Mehdad, Scott Yih. 

*Findings of the Association for Computational Linguistics: NAACL 2022.*[[pdf](https://aclanthology.org/2022.findings-naacl.115/)]

**DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models**
Ranchi Zhao, Zhen Leng Thai, Yifan Zhang, Shengding Hu, Jie Zhou, Yunqi Ba, Jie Cai, Zhiyuan Liu, Maosong Sun. 

*EMNLP 2024.*[[pdf](https://aclanthology.org/2024.emnlp-main.83/)]

**MM1: Methods, Analysis and Insights from Multimodal LLM Pre-training**
Brandon McKinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Anton Belyi, Haotian Zhang, Karanjeet Singh, Doug Kang, Hongyu Hè, Max Schwarzer, Tom Gunter, Xiang Kong, Aonan Zhang, Jianyu Wang, Chong Wang, Nan Du, Tao Lei, Sam Wiseman, Mark Lee, Zirui Wang, Ruoming Pang, Peter Grasch, Alexander Toshev, Yinfei Yang. 

*ECCV 2024.*[[pdf](https://arxiv.org/abs/2403.09611)]

**Learning Transferable Visual Models From Natural Language Supervision**
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 

*Proceedings of the 38th International Conference on Machine Learning, PMLR 139:8748-8763, 2021.*[[pdf](https://proceedings.mlr.press/v139/radford21a.html)]

**Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision**
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, Tom Duerig. 

*Proceedings of the 38th International Conference on Machine Learning, PMLR 139:4904-4916, 2021.* [[pdf](https://proceedings.mlr.press/v139/jia21b.html)]

**ShareGPT4V: Improving Large Multi-modal Models with Better Captions**
Lin Chen, Jinsong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, Dahua Lin. 

*ECCV 2024.*[[pdf](https://arxiv.org/abs/2311.12793)]

**VeCLIP: Improving CLIP Training via Visual-Enriched Captions**

Zhengfeng Lai, Haotian Zhang, Bowen Zhang, Wentao Wu, Haoping Bai, Aleksei Timofeev, Xianzhi Du, Zhe Gan, Jiulong Shan, Chen-Nee Chuah, Yinfei Yang, Meng Cao. 

*ECCV 2024.*[[pdf](https://arxiv.org/abs/2310.07699)]

**Dense X Retrieval: What Retrieval Granularity Should We Use?**
Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao, Hongming Zhang, Dong Yu. 

*EMNLP 2024.*[[pdf](https://aclanthology.org/2024.emnlp-main.845/)]

**Scalable and Domain-General Abstractive Proposition Segmentation**
Mohammad Javad Hosseini, Yang Gao, Tim Baumgärtner, Alex Fabrikant, Reinald Kim Amplayo. 

*Findings of the Association for Computational Linguistics: EMNLP 2024.*[[pdf](https://aclanthology.org/2024.findings-emnlp.517/)]

**Thread: A Logic-Based Data Organization Paradigm for How-To Question Answering with Retrieval Augmented Generation**
Kaikai An, Fangkai Yang, Liqun Li, Junting Lu, Sitao Cheng, Shuzheng Si, Lu Wang, Pu Zhao, Lele Cao, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang, Baobao Chang. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2406.13372)]

**Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment**
Jinhao Jiang, Junyi Li, Wayne Xin Zhao, Yang Song, Tao Zhang, Ji-Rong Wen. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2407.10804)]

**A Hierarchical Context Augmentation Method to Improve Retrieval-Augmented LLMs on Scientific Papers** 
Tian-Yi Che, Xian-Ling Mao, Tian Lan, Heyan Huang

*In KDD '24: Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2024, pp. 243 - 254.* [[pdf](https://doi.org/10.1145/3637528.3671847)] 

**From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models**

Xumeng Wen, Han Zhang, Shun Zheng, Wei Xu, Jiang Bian

*arXiv:2310.07338 [cs.LG]. Accepted by KDD 2024.* [[pdf](https://arxiv.org/abs/2310.07338v4)]



#### 2.2.5 Data Selection

**Improving Pretraining Data Using Perplexity Correlations**

Tristan Thrush, Christopher Potts, Tatsunori Hashimoto

*ICLR 2025* [[pdf](https://iclr.cc/virtual/2025/poster/28733)]

**Bag of Tricks for Efficient Text Classification**

Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov

*Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers (EACL 2017)* [[pdf](https://aclanthology.org/E17-2068.pdf)]

**SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models**

Yu Yang, Siddhartha Mishra, Jeffrey Chiang, Baharan Mirzasoleiman

*NeurIPS 2024* [[pdf](https://neurips.cc/virtual/2024/poster/95679)]

**Datamodels: Understanding Predictions with Data and Data with Predictions**

Andrew Ilyas, Sung Min Park, Logan Engstrom, Guillaume Leclerc, Aleksander Madry

*Proceedings of the 39th International Conference on Machine Learning, PMLR 162:9525-9587, 2022* [[pdf](https://proceedings.mlr.press/v162/ilyas22a.html)]

**LESS: Selecting Influential Data for Targeted Instruction Tuning**

Mengzhou Xia, Sadhika Malladi, Suchin Gururangan, Sanjeev Arora, Danqi Chen

*ICML 2024* [[pdf](https://doi.org/10.48550/arXiv.2402.04333)]

**DavIR: Data Selection via Implicit Reward for Large Language Models**

Haotian Zhou, Tingkai Liu, Qianli Ma, Yufeng Zhang, Jianbo Yuan, Pengfei Liu, Yang You, Hongxia Yang

*arXiv:2310.13008 [cs.LG].* [[pdf](https://arxiv.org/abs/2310.13008v2)] 

**Efficient Continual Pre-training for Building Domain Specific Large Language Models**
*Yong Xie, Karan Aggarwal, Aitzaz Ahmad.*

*Findings of the Association for Computational Linguistics: ACL 2024.*[[pdf](https://aclanthology.org/2024.findings-acl.606/)]

**Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis**
*Ruiyang Qin, Jun Xia, Zhenge Jia, Meng Jiang, Ahmed Abbasi, Peipei Zhou, Jingtong Hu, Yiyu Shi.*

*DAC '24: Proceedings of the 61st ACM/IEEE Design Automation Conference, Article No. 29, Pages 1-6, 2024.*[[pdf](https://doi.org/10.1145/3649329.3655665)]

**Autonomous Data Selection with Language Models for Mathematical Texts**
*Yifan Zhang, Yifan Luo, Yang Yuan, Andrew Chi-Chih Yao.*

*ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models.*[[pdf](https://arxiv.org/abs/2402.07625)]

**A Survey on Data Selection for Language Models**

Alon Albalak, Yanai Elazar, Sang Michael Xie, Shayne Longpre, Nathan Lambert, Xinyi Wang, Niklas Muennighoff, Bairu Hou, Liangming Pan, Haewon Jeong, Colin Raffel, Shiyu Chang, Tatsunori Hashimoto, William Yang Wang.

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2402.16827)]

**A Survey on Data Selection for LLM Instruction Tuning**
Jiahao Wang, Bolin Zhang, Qianlong Du, Jiajun Zhang, Dianhui Chu. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2402.05123)]

**D4: Improving LLM Pretraining via Document De-Duplication and Diversification**
*Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari Morcos.*

*NeurIPS 2023.*[[pdf](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a8f8cbd7f7a5fb2c837e578c75e5b615-Abstract-Datasets_and_Benchmarks.html)]

**How to Train Data-Efficient LLMs**
Noveen Sachdeva, Benjamin Coleman, Wang-Cheng Kang, Jianmo Ni, Lichan Hong, Ed H. Chi, James Caverlee, Julian McAuley, Derek Zhiyuan Cheng. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2402.09668)]

**ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning**
Yang Wu, Huayi Zhang, Yizheng Jiao, Lin Ma, Xiaozhong Liu, Jinhong Yu, Dongyu Zhang, Dezhi Yu, Wei Xu. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2412.00631)]

**Data Acquisition for Improving Model Confidence**
*Yifan Li, Xiaohui Yu, Nick Koudas.*

*Proceedings of the ACM on Management of Data, Volume 2, Issue 3, Article No. 131, Pages 1-25, 2024.*[[pdf](https://doi.org/10.1145/3654934)]

**Active Learning Principles for In-Context Learning with Large Language Models**
*Katerina Margatina, Timo Schick, Nikolaos Aletras, Jane Dwivedi-Yu.*

*Findings of the Association for Computational Linguistics: EMNLP 2023.*[[pdf](https://aclanthology.org/2023.findings-emnlp.334)]

**Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection**
Costas Mavromatis, Balasubramaniam Srinivasan, Zhengyuan Shen, Jiani Zhang, Huzefa Rangwala, Christos Faloutsos, George Karypis. 

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2310.20046)]

**RETRIEVE: coreset selection forsemi-supervised learning**
*Krishnateja Killamsetty, Xujiang Zhao, Feng Chen, Rishabh Iyer*

*NeurIPS 2021.*[[pdf](https://dl.acm.org/doi/10.5555/3540261.3541371)]

**Influential Language Data Selection via Gradient Trajectory Pursuit**
Zhiwei Deng, Tao Li, Yang Li. 

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2410.16710)]

**Most Influential Subset Selection: Challenges, Promises, and Beyond**
*Yuzheng Hu, Pingbang Hu, Han Zhao, Jiaqi W. Ma.*

*NeurIPS 2024.*[[pdf](https://arxiv.org/abs/2409.18153)]
**Influence Scores at Scale for Efficient Language Data Sampling**
*Nikhil Anand, Joshua Tan, Maria Minakova.*

*EMNLP 2023.* [[pdf](https://aclanthology.org/2023.emnlp-main.152)]

**CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language Model Pre-training**

David Brandfonbrener, Hanlin Zhang, Andreas Kirsch, Jonathan Richard Schwarz, Sham Kakade

*arXiv:2406.10670 [cs.LG]. Presented at NeurIPS.* [[pdf](https://arxiv.org/abs/2406.10670v3)]

**Harnessing Diversity for Important Data Selection in Pretraining Large Language Models**

Chi Zhang, Huaping Zhong, Kuan Zhang, Chengliang Chai, Rui Wang, Xinlin Zhuang, Tianyi Bai, Jiantao Qiu, Lei Cao, Ju Fan, Ye Yuan, Guoren Wang, Conghui He

*arXiv:2409.16986 [cs.AI]. Submitted to ICLR 2025.* [[pdf](https://arxiv.org/abs/2409.16986v2)]

**DSDM: model-aware dataset selection with datamodels**

Logan Engstrom, Axel Feldmann, Aleksander Mądry

*ICML'24: Proceedings of the 41st International Conference on Machine Learning* [[pdf](https://dl.acm.org/doi/10.5555/3692070.3692568)]

**Data Selection for Language Models via Importance Resampling**

Sang Michael Xie, Shibani Santurkar, Tengyu Ma, Percy Liang

*NeurIPS 2023* [[pdf](https://doi.org/10.48550/arXiv.2302.03169)]



### 2.3 Data Distillation

#### 2.3.1  Data Mixing

**Maximize Your Data's Potential: Enhancing LLM Accuracy with Two-Phase Pretraining**
*Steven Feng, Shrimai Prabhumoye, Kezhi Kong, Dan Su, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro.*

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2412.15285)]

**SlimPajama-DC: Understanding Data Combinations for LLM Training**
*Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Zhengzhong Liu, Hongyi Wang, Bowen Tan, Joel Hestness, Natalia Vassilieva, Daria Soboleva, Eric Xing.*

*arxiv 2023.*[[pdf](https://arxiv.org/abs/2309.10818)]

**An overview of bilevel optimization**
*Benoît Colson, Patrice Marcotte, Gilles Savard.*

*Annals of Operations Research, Volume 153, Issue 1, Pages 235-256, 2007.*[[pdf](https://link.springer.com/article/10.1007/s10479-007-0176-2)]

**Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models**
*Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Reza Haf*

*EMNLP 2024.*[[pdf](https://aclanthology.org/2024.emnlp-main.787)]

**ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting**
*Rui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xiaoyu Wang, Tong Zhang.*

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2406.19976)]

**DoGE: Domain Reweighting with Generalization Estimation**
*Simin Fan, Matteo Pagliardini, Martin Jaggi.*

*arxiv 2023.*[[pdf](https://doi.org/10.48550/arXiv.2310.15393)]

**DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining**
*Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V. Le, Tengyu Ma, Adams Wei Yu.*

*NeurIPS 2023.*[[pdf](https://arxiv.org/abs/2305.10429)]

**Task-level Distributionally Robust Optimization for Large Language Model-based Dense Retrieval**
*Guangyuan Ma, Yongliang Ma, Xing Wu, Zhenpeng Su, Ming Zhou, Songlin Hu.*

*AAAI 2025.*[[pdf](https://arxiv.org/abs/2408.10613)]

**Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training**
*Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Chen Qi, Peng Cheng.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2411.14318)]

**RegMix: Data Mixture as Regression for Language Model Pre-training**
*Qian Liu, Xiaosen Zheng, Niklas Muennighoff, Guangtao Zeng, Longxu Dou, Tianyu Pang, Jing Jiang, Min Lin.*

*ICLR 2025.* [[pdf](https://doi.org/10.48550/arXiv.2407.01492)]

**BiMix: Bivariate Data Mixing Law for Language Model Pretraining**

Ce Ge, Zhijian Ma, Daoyuan Chen, Yaliang Li, Bolin Ding.

*arxiv 2024.* [[pdf](https://arxiv.org/abs/2405.14908)]

**CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**
*Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan.*

*EMNLP 2024.* [[pdf](https://aclanthology.org/2024.emnlp-main.903)]

**Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance**
*Jiasheng Ye, Peiju Liu, Tianxiang Sun, Yunhua Zhou, Jun Zhan, Xipeng Qiu.*

*arxiv 2024.* [[pdf](https://arxiv.org/abs/2403.16952)]

**Efficient Online Data Mixing For Language Model Pre-Training**
*Alon Albalak, Liang-Ming Pan, Colin Raffel, William Yang Wang.*

*Workshop: Third Workshop on Efficient Natural Language and Speech Processing (ENLSP-III).* [[pdf](https://nips.cc/virtual/2023/81179)]

**D-CPT Law: Domain-specific Continual Pre-Training Scaling Law for Large Language Models**
*Haoran Que, Jiaheng Liu, Ge Zhang, Chenchen Zhang, Xingwei Qu, Yinghao Ma, Feiyu Duan, Zhiqi Bai, Jiakai Wang, Yuanxing Zhang, Xu Tan, Jie Fu, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2406.01375)]

**Data Proportion Detection for Optimized Data Management for Large Language Models**
*Hao Liang, Keshi Zhao, Yajie Yang, Bin Cui, Guosheng Dong, Zenan Zhou, Wentao Zhang.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2409.17527)]

**Qwen Technical Report**

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, Tianhang Zhu

*arXiv:2309.16609 [cs.CL].* [[pdf](https://arxiv.org/abs/2309.16609v1)]

**Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models**

Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Yu Han, Hao Wang

*arXiv:2403.03432 [cs.CL]. Accepted at COLING24.* [[pdf](https://arxiv.org/abs/2403.03432v1)]

**LightGBM: a highly efficient gradient boosting decision tree** Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu

*In NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017, pp. 3149 - 3157.* [[pdf](https://dl.acm.org/doi/10.5555/3294996.3295074)] 

**Scalable Data Ablation Approximations for Language Models through Modular Training and Merging**

Clara Na, Ian Magnusson, Ananya Harsh Jha, Tom Sherborne, Emma Strubell, Jesse Dodge, Pradeep Dasigi

*arXiv:2410.15661 [cs.CL]. Accepted at EMNLP 2024.* [[pdf](https://arxiv.org/abs/2410.15661v1)]



#### 2.3.2 Data Synthesis and Augmentation

**Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling**

Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, Yuxiao Dong

*arXiv:2501.11651 [cs.LG] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2501.11651)]

**LLMs Can Easily Learn to Reason from Demonstrations: Structure, Not Content, Is What Matters!**

Dacheng Li, Shiyi Cao, Tyler Griggs, Shu Liu, Xiangxi Mo, Eric Tang, Sumanth Hegde, Kourosh Hakhamaneshi, Shishir G. Patil, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica

*arXiv:2502.07374 [cs.AI] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.07374)]

**Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search**

Maohao Shen, Guangtao Zeng, Zhenting Qi, Zhang-Wei Hong, Zhenfang Chen, Wei Lu, Gregory Wornell, Subhro Das, David Cox, Chuang Gan

*arXiv:2502.02508 [cs.CL] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.02508)]

**LIMO: Less is More for Reasoning**

Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu

*arXiv:2502.03387 [cs.CL] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.03387)]

**LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives**
*Luísa Shimabucoro, Sebastian Ruder, Julia Kreutzer, Marzieh Fadaee, Sara Hooker.*

*EMNLP 2024.* [[pdf](https://aclanthology.org/2024.emnlp-main.521)]

**Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models**
Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang, Yuxian Gu, Xin Cheng, Xun Wang, Si-Qing Chen, Li Dong, Wei Lu, Zhifang Sui, Benyou Wang, Wai Lam, Furu Wei. 

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2402.13064)]

**Large Language Models are Human-Level Prompt Engineers**
*Yongchao Zhou, Andrei Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba.*

*ICLR 2023.* [[pdf](https://iclr.cc/virtual/2023/poster/10850)]

**Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data**
*Shenglai Zeng, Jiankun Zhang, Pengfei He, Jie Ren, Tianqi Zheng, Hanqing Lu, Han Xu, Hui Liu, Yue Xing, Jiliang Tang.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2406.14773)]

**Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning**
*Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, Weizhu Chen.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2403.02333)]

**Augmenting Math Word Problems via Iterative Question Composing**
*Haoxiong Liu, Yifan Zhang, Yifan Luo, Andrew Chi-Chih Yao.*

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2401.09003)]

**MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data**
Yinya Huang, Xiaohan Lin, Zhengying Liu, Qingxing Cao, Huajian Xin, Haiming Wang, Zhenguo Li, Linqi Song, Xiaodan Liang. 

*ICLR 2024.* [[pdf](https://arxiv.org/abs/2402.08957v3)]

**Self-Instruct: Aligning Language Models with Self-Generated Instructions**
*Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi.*

*ACL 2023.* [[pdf](https://aclanthology.org/2023.acl-long.754)]

**Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation**
*Xinyu Tang, Richard Shin, Huseyin A. Inan, Andre Manoel, Fatemehsadat Mireshghallah, Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Robert Sim*

*arxiv 2023.* [[pdf](https://doi.org/10.48550/arXiv.2309.11765)]

**AgentInstruct: Toward Generative Teaching with Agentic Flows**
Arindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan, Dany Rouhana, Andres Codas, Yadong Lu, Wei-ge Chen, Olga Vrousgos, Corby Rosset, Fillipe Silva, Hamed Khanpour, Yash Lara, Ahmed Awadallah. 

*arxiv 2024.* [[pdf](https://doi.org/10.48550/arXiv.2407.03502)]

**JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models**
*Kun Zhou, Beichen Zhang, Jiapeng Wang, Zhipeng Chen, Wayne Xin Zhao, Jing Sha, Zhichao Sheng, Shijin Wang, Ji-Rong Wen.*

*arxiv 2024.*[[pdf](https://arxiv.org/abs/2405.14365)]

**Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback**
*Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, Jared Kaplan.*

*arxiv 2022.*[[pdf](https://doi.org/10.48550/arXiv.2204.05862)]

**Differentially Private Synthetic Data via Foundation Model APIs 2: Text**

Chulin Xie, Zinan Lin, Arturs Backurs, Sivakanth Gopi, Da Yu, Huseyin A Inan, Harsha Nori, Haotian Jiang, Huishuai Zhang, Yin Tat Lee, Bo Li, Sergey Yekhanin

*arXiv:2403.01749 [cs.CL]. ICML'24 Spotlight.* [[pdf](https://arxiv.org/abs/2403.01749v2)] 

**WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions**

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Qingwei Lin, Daxin Jiang

*ICLR 2024.* [[pdf](https://iclr.cc/virtual/2024/poster/19164)]

**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena**

Lianmin Zheng, Wei - Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica

*arXiv:2306.05685 [cs.CL]. Presented at NeurIPS 2023 Datasets and Benchmarks Track.* [[pdf](https://arxiv.org/abs/2306.05685v4)]

**Let's Verify Step by Step**

Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe

*arXiv:2305.20050 [cs.LG] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2305.20050)]

**Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations**

Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, Zhifang Sui

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024* [[pdf](https://aclanthology.org/2024.acl-long.510)]



#### 2.3.3 End-to-End Data Processing Pipelines

*2.2.8.1 Typical data processing frameworks*

**Data-Juicer: A One-Stop Data Processing System for Large Language Models**
*Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, Jingren Zhou.*

*SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data, Pages 120-134, 2024.*[[pdf](https://doi.org/10.1145/3626246.3653385)]

**Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models**

Hyunbyung Park, Sukyung Lee, Gyoungjin Gim, Yungi Kim, Dahyun Kim, Chanjun Park

*arXiv:2403.19340 [cs.CL].* [[pdf](https://arxiv.org/abs/2403.19340v1)]

**An Integrated Data Processing Framework for Pretraining Foundation Models**

Yiding Sun, Feng Wang, Yutao Zhu, Wayne Xin Zhao, Jiaxin Mao

*In SIGIR '24: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024, pp. 2713 - 2718.* [[pdf](https://doi.org/10.1145/3626772.3657671)]



*2.2.8.2 Typical data pipelines*

**Query Rewriting via Large Language Models**

Jie Liu, Barzan Mozafari

*arXiv:2403.09060 [cs.DB] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.09060)]

**Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction**

Adrien Barbaresi

*Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, 2021* [[pdf](https://aclanthology.org/2021.acl-demo.15.pdf)]

**LP Data Pipeline: Lightweight, Purpose-driven Data Pipeline for Large Language Models**

Yungi Kim, Hyunsoo Ha, Seonghoon Yang, Sukyung Lee, Jihoo Kim, Chanjun Park

*arXiv:2411.11289 [cs.CL].* [[pdf](https://arxiv.org/abs/2411.11289v1)]

**The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale** 

*Guilherme Penedo, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, Thomas Wolf. NeurIPS 2024.* [[pdf](https://doi.org/10.48550/arXiv.2406.17557)] 

**DataComp-LM: In search of the next generation of training sets for language models**

Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng - Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El - Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar

*arXiv:2406.11794 [cs.LG].* [[pdf](https://arxiv.org/abs/2406.11794v3)]

**The RefinedWeb dataset for falcon LLM: outperforming curated corpora with web data only** Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Hamza Alobeidli, Alessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, Julien Launay 

*arXiv:2306.01116 [cs.CL]. Presented at NIPS '23: Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023, Article No.: 3464, pp. 79155 - 79172.* [[pdf](https://arxiv.org/abs/2306.01116v1)] 

**Scaling Language Models: Methods, Analysis & Insights from Training Gopher**

Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, Geoffrey Irving

*arXiv:2112.11446 [cs.CL].* [[pdf](https://arxiv.org/abs/2112.11446v2)]

**Exploring the limits of transfer learning with a unified text-to-text transformer**

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu

*arXiv:1910.10683 [cs.LG]. Published in The Journal of Machine Learning Research, Volume 21, Issue 1, 2020, Article No.: 140, pp. 5485 - 5551.* [[pdf](https://arxiv.org/abs/1910.10683v4)]

**Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset**

Dan Su, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

*arXiv:2412.02595 [cs.CL].* [[pdf](https://arxiv.org/abs/2412.02595v1)] 

**LLaMA: Open and Efficient Foundation Language Models**

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie - Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample

*arXiv:2302.13971 [cs.CL].* [[pdf](https://arxiv.org/abs/2302.13971v1)]

**CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data**

Guillaume Wenzek, Marie - Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, Edouard Grave

*In Proceedings of the Twelfth Language Resources and Evaluation Conference, 2020, pp. 4003 - 4012.* [[pdf](https://aclanthology.org/2020.lrec-1.494/)]

**Removing Boilerplate and Duplicate Content from Web Corpora**

Jan Pomikálek. 

Published in 2011, in the field of Physics.[[pdf](https://docslib.org/doc/706394/removing-boilerplate-and-duplicate-content-from-web-corpora)]

**Baichuan 2: Open Large-scale Language Models** 

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, JunTao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu. 

*arXiv:2309.10305 [cs.CL].* [[pdf](https://doi.org/10.48550/arXiv.2309.10305)] 

**Oasis: data curation and assessment system for pretraining of large language models**

Tong Zhou, Yubo Chen, Pengfei Cao, Kang Liu, Shengping Liu, Jun Zhao

*In IJCAI '24: Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, 2024, Article No.: 1048, pp. 8855 - 8859.* [[pdf](https://doi.org/10.24963/ijcai.2024/1048)]



*2.2.8.3 Orchestration of data pipelines*

**Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development**

Daoyuan Chen, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou

*arXiv:2407.11784 [cs.AI].* [[pdf](https://arxiv.org/abs/2407.11784v2)]



#### 2.3.4 Utilities

**Densing Law of LLMs**

Chaojun Xiao, Jie Cai, Weilin Zhao, Guoyang Zeng, Biyuan Lin, Jie Zhou, Zhi Zheng, Xu Han, Zhiyuan Liu, Maosong Sun

*arXiv:2412.04315 [cs.AI]* [[pdf](https://arxiv.org/abs/2412.04315)]



*2.2.9.2 Data Provenance for LLMs* 

**A comprehensive survey on data provenance: State-of-the-art approaches and their deployments for IoT security enforcement**

Md Morshed Alam, Weichao Wang

*Journal of Computer Security, Volume 29, Issue 4, pp. 423 - 446.* [[pdf](https://doi.org/10.3233/JCS-200108)]

**Undetectable Watermarks for Language Models**

Miranda Christ, Sam Gunn, Or Zamir

*PMLR 2024.* [[pdf](https://arxiv.org/abs/2306.09194v1)]

**Publicly-Detectable Watermarking for Language Models**

Jaiden Fairoze, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Mingyuan Wang

*arXiv:2310.18491 [cs.LG]*[[pdf](https://arxiv.org/abs/2310.18491)]

**A Watermark for Large Language Models**

John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, Tom Goldstein

*ICML 2023.* [[pdf](https://arxiv.org/abs/2301.10226v4)] 

**An Unforgeable Publicly Verifiable Watermark for Large Language Models**

Aiwei Liu, Leyi Pan, Xuming Hu, Shu'ang Li, Lijie Wen, Irwin King, Philip S. Yu

*ICLR2024* [[pdf](https://arxiv.org/pdf/2307.16230v7.pdf)]

**Provable Robust Watermarking for AI-Generated Text**

Xuandong Zhao, Prabhanjan Ananth, Lei Li, Yu-Xiang Wang

*ICLR2024* [[pdf](https://arxiv.org/pdf/2306.17439v2.pdf)]

**Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature**

Tong Zhou, Xuandong Zhao, Xiaolin Xu, Shaolei Ren

*NeurIPS 2024* [[pdf](https://arxiv.org/pdf/2406.01946v3.pdf)]



*2.2.9.3 Data Visualization*

**Data-Juicer: A One-Stop Data Processing System for Large Language Models**
Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, Jingren Zhou

*SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data, Pages 120-134, 2024.*[[pdf](https://doi.org/10.1145/3626246.3653385)]



*2.2.9.4 Constructing Dense LLMs*

**Training compute-optimal large language models**

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al.

*NIPS'22* [[pdf](https://dl.acm.org/doi/10.5555/3600270.3602446)]

**Scaling Laws for Neural Language Models**

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei

*arXiv:2001.08361 [cs.LG].* [[pdf](https://arxiv.org/abs/2001.08361)]

**InternLM2 Technical Report**

Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiaoyi Dong, Haodong Duan, Qi Fan, Zhaoye Fei, Yang Gao, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, Aijia Guo, Qipeng Guo, Conghui He, Yingfan Hu, Ting Huang, Tao Jiang, Penglong Jiao, Zhenjiang Jin, Zhikai Lei, Jiaxing Li, Jingwen Li, Linyang Li, Shuaibin Li, Wei Li, Yining Li, Hongwei Liu, Jiangning Liu, Jiawei Hong, Kaiwen Liu, Kuikun Liu, Xiaoran Liu, Chengqi Lv, Haijun Lv, Kai Lv, Li Ma, Runyuan Ma, Zerun Ma, Wenchang Ning, Linke Ouyang, Jiantao Qiu, Yuan Qu, Fukai Shang, Yunfan Shao, Demin Song, Zifan Song, Zhihao Sui, Peng Sun, Yu Sun, Huanze Tang, Bin Wang, Guoteng Wang, Jiaqi Wang, Jiayu Wang, Rui Wang, Yudong Wang, Ziyi Wang, Xingjian Wei, Qizhen Weng, Fan Wu, Yingtong Xiong, Chao Xu, Ruiliang Xu, Hang Yan, Yirong Yan, Xiaogui Yang, Haochen Ye, Huaiyuan Ying, Jia Yu, Jing Yu, Yuhang Zang, Chuyu Zhang, Li Zhang, Pan Zhang, Peng Zhang, Ruijie Zhang, Shuo Zhang, Songyang Zhang, Wenjian Zhang, Wenwei Zhang, Xingcheng Zhang, Xinyue Zhang, Hui Zhao, Qian Zhao, Xiaomeng Zhao, Fengzhe Zhou, Zaida Zhou, Jingming Zhuo, Yicheng Zou, Xipeng Qiu, Yu Qiao, Dahua Lin

*arXiv:2403.17297 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.17297)]

**Process Reinforcement through Implicit Rewards**

Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, Jiarui Yuan, Huayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu Han, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Ning Ding

*arXiv:2502.01456 [cs.LG] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.01456)]

**DeepSeek-V3 Technical Report**

DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J.L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R.J. Chen, R.L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S.S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W.L. Xiao, Wangding Zeng et al. (100 additional authors not shown)

*arXiv:2412.19437 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2412.19437)]

**MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies**

Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, Xinrong Zhang, Zheng Leng Thai, Kaihuo Zhang, Chongyi Wang, Yuan Yao, Chenyang Zhao, Jie Zhou, Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun

*arXiv:2404.06395 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2404.06395)]

**Mistral 7B**

Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed

*arXiv:2310.06825 [cs.CL] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2310.06825)]

**Mixtral of Experts**

Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed

*arXiv:2401.04088 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2401.04088)]

**Linearizing Large Language Models**

Jean Mercat, Igor Vasiljevic, Sedrick Keh, Kushal Arora, Achal Dave, Adrien Gaidon, Thomas Kollar

*arXiv:2405.06640 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2405.06640)]

**MiniMax-01: Scaling Foundation Models with Lightning Attention**

MiniMax, Aonian Li, Bangwei Gong, Bo Yang, Boji Shan, Chang Liu, Cheng Zhu, Chunhao Zhang, Congchao Guo, Da Chen, Dong Li, Enwei Jiao, Gengxin Li, Guojun Zhang, Haohai Sun, Houze Dong, Jiadai Zhu, Jiaqi Zhuang, Jiayuan Song, Jin Zhu, Jingtao Han, Jingyang Li, Junbin Xie, Junhao Xu, Junjie Yan, Kaishun Zhang, Kecheng Xiao, Kexi Kang, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Zheng, Linbo Chai, Long Xing, Meizhi Ju, Mingyuan Chi, Mozhi Zhang, Peikai Huang, Pengcheng Niu, Pengfei Li, Pengyu Zhao, Qi Yang, Qidi Xu, Qiexiang Wang, Qin Wang, Qiuhui Li, Ruitao Leng, Shengmin Shi, Shuqi Yu, Sichen Li, Songquan Zhu, Tao Huang, Tianrun Liang, Weigao Sun, Weixuan Sun, Weiyu Cheng, Wenkai Li, Xiangjun Song, Xiao Su, Xiaodong Han, Xinjie Zhang, Xinzhu Hou, Xu Min, Xun Zou, Xuyang Shen, Yan Gong, Yingjie Zhu, Yipeng Zhou, Yiran Zhong, Yongyi Hu, Yuanxiang Fan, Yue Yu, Yufeng Yang, Yuhao Li, Yunan Huang, Yunji Li, Yunpeng Huang, Yunzhi Xu, Yuxin Mao, Zehan Li, Zekang Li, Zewei Tao, Zewen Ying, Zhaoyang Cong, Zhen Qin, Zhenhua Fan, Zhihang Yu, Zhuo Jiang, Zijia Wu

*arXiv:2501.08313 [cs.CL] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2501.08313)]

**GPT-4 Technical Report**

OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain et al. (181 additional authors not shown)

*arXiv:2303.08774 [cs.CL] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2303.08774)]

**LLaMA: Open and Efficient Foundation Language Models**

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample

*arXiv:2302.13971 [cs.CL] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2302.13971)]

**Densing Law of LLMs**

Chaojun Xiao, Jie Cai, Weilin Zhao, Guoyang Zeng, Biyuan Lin, Jie Zhou, Zhi Zheng, Xu Han, Zhiyuan Liu, Maosong Sun

*arXiv:2412.04315 [cs.AI]* [[pdf](https://arxiv.org/abs/2412.04315)]



### 2.4 Data Storage for LLM

#### 2.4.1 Data Storage For Training

*2.3.1.1 Training Data Storage*

**HDFS Architecture Guide**

D. Borthakur et al.

*Hadoop Apache Project, 53(1-13):2, 2008* [[pdf](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)]

**tf.data service: A Case for Disaggregating ML Input Data Processing**

Andrew Audibert, Yang Chen, Dan Graur, Ana Klimovic, Jiří Šimša, Chandramohan A. Thekkath

*SoCC '23: Proceedings of the 2023 ACM Symposium on Cloud Computing* [[pdf](https://doi.org/10.1145/3620678.3624666)]

**I/O Characterization and Performance Evaluation of BeeGFS for Deep Learning**

Fahim Chowdhury, Yue Zhu, Todd Heer, Saul Paredes, Adam Moody, Robin Goldstone, Kathryn Mohror, Weikuan Yu

*ICPP '19: Proceedings of the 48th International Conference on Parallel Processing* [[pdf](https://doi.org/10.1145/3337821.3337902)]

**Fluid: Dataset Abstraction and Elastic Acceleration for Cloud-native Deep Learning Training Jobs**

Rong Gu, Kai Zhang, Zhihao Xu, Yang Che, Bin Fan, Haojun Hou

*2022 IEEE 38th International Conference on Data Engineering (ICDE)* [[pdf](https://doi.org/10.1109/ICDE53745.2022.00209)]

**CC - GPX: Extracting High-Quality Annotated Geospatial Data from Common Crawl**

Ilya Ilyankou, Meihui Wang, Stefano Cavazzi, James Haworth

*SIGSPATIAL '24: Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems* [[pdf](https://doi.org/10.1145/3678717.3691215)]

**High Performance I/O**

Adrian Jackson, Fiona Reid, Joachim Hein, Alejandro Soba, Xavier Saez

*2011 19th International Euromicro Conference on Parallel, Distributed and Network - Based Processing* [[pdf](https://ieeexplore.ieee.org/abstract/document/5739034)]

**Quiver: An Informed Storage Cache for Deep Learning**

Abhishek Kumar, Muthian Sivathanu

*USENIX Conference on File and Storage Technologies, 23 February 2020* [[pdf](https://www.usenix.org/conference/fast20/presentation/kumar)]

**An Overview of Data Warehouse and Data Lake in Modern Enterprise Data Management**
*Athira Nambiar, Divyansh Mundra. Big Data and Cognitive Computing, 2022.*[[pdf](https://doi.org/10.3390/bdcc6040132)]

**I/O Bottleneck Investigation in Deep Learning Systems**

S. Pumma, Min Si, Wu-chun Feng, P. Balaji

*Published 2018, Computer Science* [[pdf](https://www.semanticscholar.org/paper/I-O-Bottleneck-Investigation-in-Deep-Learning-Pumma-Si/e1486bf2783f5da4cf9a3785f44c7efdb0793c33)]

**The Image Calculator: 10x Faster Image-AI Inference by Replacing JPEG with Self-designing Storage Format**
Utku Sirin, Stratos Idreos

*Proceedings of the ACM on Management of Data, 2024.*[[pdf](https://doi.org/10.1145/3639307)]

**Google Cloud Platform for Data Science: A Crash Course on Big Data, Machine Learning, and Data Analytics Services**

Dr. Shitalkumar R. Sukhdeve, Sandika S. Sukhdeve

*Apress, 2023* [[Book Link](https://link.springer.com/book/10.1007/978-1-4842-9688-2)]

**SUFS: A Generic Storage Usage Forecasting Service Through Adaptive Ensemble Learning**
*Luming Sun, Shijin Gong, Tieying Zhang, Fuxin Jiang, Zhibing Zhao, Jianjun Chen. 2023 IEEE 39th International Conference on Data Engineering (ICDE), 2023.*[[pdf](https://ieeexplore.ieee.org/document/10184683)]

**SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters**

Hanyu Zhao, Zhenhua Han, Zhi Yang, Quanlu Zhang, Mingxia Li, Fan Yang, Qianxi Zhang, Binyang Li, Yuqing Yang, Lili Qiu, Lintao Zhang, Lidong Zhou

*EuroSys '23: Proceedings of the Eighteenth European Conference on Computer Systems* [[pdf](https://doi.org/10.1145/3552326.3567499)]

**Cachew: Machine Learning Input Data Processing as a Service**

Dan Graur, Damien Aymon, Dan Kluser, Tanguy Albrici, Chandramohan A. Thekkath, Ana Klimovic

*2022 USENIX Annual Technical Conference (USENIX ATC '22)* [[pdf](https://www.usenix.org/conference/atc22/presentation/graur)]

**Pecan: cost-efficient ML data preprocessing with automatic transformation ordering and hybrid placement**

Dan Graur, Oto Mraz, Muyu Li, Sepehr Pourghannad, Chandramohan A. Thekkath, Ana Klimovic

*USENIX ATC'24: Proceedings of the 2024 USENIX Conference on Usenix Annual Technical Conference* [[pdf](https://dl.acm.org/doi/10.5555/3691992.3692032)]

**cedar: Optimized and Unified Machine Learning Input Data Pipelines**

Mark Zhao, Emanuel Adamiak, Christos Kozyrakis

*PVLDB Volume 18, Issue 2* [[pdf](https://doi.org/10.48550/arXiv.2401.08895)]

**Tectonic-Shift: A Composite Storage Fabric for Large-Scale ML Training**

Mark Zhao, Satadru Pan, Niket Agarwal, Zhaoduo Wen, David Xu, Anand Natarajan, Pavan Kumar, Shiva Shankar P, Ritesh Tijoriwala, Karan Asher, Hao Wu, Aarti Basant, Daniel Ford, Delia David, Nezih Yigitbasi, Pratap Singh, Carole-Jean Wu, Christos Kozyrakis

*2023 USENIX Annual Technical Conference (USENIX ATC 23)* [[pdf](https://www.usenix.org/conference/atc23/presentation/zhao)]



*2.3.1.2 Model Data Storage*

**An Empirical Study of Safetensors' Usage Trends and Developers' Perceptions**

Beatrice Casey, Kaia Damian, Andrew Cotaj, Joanna C. S. Santos

*arXiv:2501.02170 [cs.SE] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2501.02170)]

**MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs**
*Ziheng Jiang, Haibin Lin, Yinmin Zhong, Qi Huang, Yangrui Chen, Zhi Zhang, Yanghua Peng, Xiang Li, Cong Xie, Shibiao Nong, Yulu Jia, Sun He, Hongmin Chen, Zhihao Bai, Qi Hou, Shipeng Yan, Ding Zhou, Yiyao Sheng, Zhuo Jiang, Haohan Xu, Haoran Wei, Zhang Zhang, Pengfei Nie, Leqi Zou, Sida Zhao, Liang Xiang, Zherui Liu, Zhe Li, Xiaoying Jia, Jianxi Ye, Xin Jin, Xin Liu. 21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24), 2024.*[[pdf](https://doi.org/10.48550/arXiv.2402.15627)]

**CheckFreq: Frequent, Fine-Grained DNN Checkpointing**

Jayashree Mohan, Amar Phanishayee, Vijay Chidambaram

*19th USENIX Conference on File and Storage Technologies (FAST 21)* [[pdf](https://www.usenix.org/conference/fast21/presentation/mohan)]

**ZeRO: memory optimizations toward training trillion parameter models**

Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He

*SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis* [[pdf](https://dl.acm.org/doi/10.5555/3433701.3433727)]

**ZeRO-infinity: breaking the GPU memory wall for extreme scale deep learning**

Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, Yuxiong He

*SC '21: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis* [[pdf](https://doi.org/10.1145/3458817.3476205)]

**ZeRO-Offload: Democratizing Billion-Scale Model Training**

Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, Yuxiong He

*USENIX ATC 2021* [[pdf](https://www.researchgate.net/profile/Jie-Ren-14/publication/348589607_ZeRO-Offload_Democratizing_Billion-Scale_Model_Training/links/602c2c2c92851c9287908616/ZeRO-Offload-Democratizing-Billion-Scale-Model-Training.pdf)]

**vDNN: virtualized deep neural networks for scalable, memory-efficient neural network design**

Minsoo Rhu, Natalia Gimelshein, Jason Clemons, Arslan Zulfiqar, Stephen W. Keckler

*MICRO - 49: The 49th Annual IEEE/ACM International Symposium on Microarchitecture* [[pdf](https://dl.acm.org/doi/10.5555/3195638.3195660)]

**ProTrain: Efficient LLM Training via Memory-Aware Techniques**

Hanmei Yang, Jin Zhou, Yao Fu, Xiaoqun Wang, Ramine Roane, Hui Guan, Tongping Liu [[pdf](https://arxiv.org/abs/2406.08334)]

**ByteCheckpoint: A Unified Checkpointing System for Large Foundation Model Development**

Borui Wan, Mingji Han, Yiyao Sheng, Yanghua Peng, Haibin Lin, Mofan Zhang, Zhichao Lai, Menghan Yu, Junda Zhang, Zuquan Song, Xin Liu, Chuan Wu

*arXiv:2407.20143 [cs.AI] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2407.20143)]

**GEMINI: Fast Failure Recovery in Distributed Training with In-Memory Checkpoints**

Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, Yida Wang

*SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles* [[pdf](https://doi.org/10.1145/3600006.3613145)]



#### 2.4.2 Data Storage for Inference

**Cost-Efficient Large Language Model Serving for Multi-turn Conversations with CachedAttention**

Bin Gao, Zhuomin He, Puru Sharma, Qingxuan Kang, Djordje Jevdjic, Junbo Deng, Xingkun Yang, Zhou Yu, Pengfei Zuo

*USENIX ATC 2024.* [[pdf](https://arxiv.org/abs/2403.19708)]

**Fast State Restoration in LLM Serving with HCache**

Shiwei Gao, Youmin Chen, Jiwu Shu

*EuroSys 2025. [[pdf](https://arxiv.org/abs/2410.05004)]

**MemServe: Context Caching for Disaggregated LLM Serving with Elastic Memory Pool**

Cunchen Hu, Heyang Huang, Junhao Hu, Jiang Xu, Xusheng Chen, Tao Xie, Chenxi Wang, Sa Wang, Yungang Bao, Ninghui Sun, Yizhou Shan

*arXiv preprint arXiv:2406.17565* [[pdf](https://arxiv.org/abs/2406.17565)]

**Efficient LLM Inference with I/O-Aware Partial KV Cache Recomputation**

Chaoyi Jiang, Lei Gao, Hossein Entezari Zarch, Murali Annavaram

*arXiv preprint arXiv:2411.17089* [[pdf](https://arxiv.org/abs/2411.17089)]

**Efficient Memory Management for Large Language Model Serving with PagedAttention**

Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, Ion Stoica

*SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3600006.3613165)]

**QUEST: query-aware sparsity for efficient long-context LLM inference**

Jiaming Tang, Yilong Zhao, Kan Zhu, Guangxuan Xiao, Baris Kasikci, Song Han

*ICML'24: Proceedings of the 41st International Conference on Machine Learning* [[pdf](https://dl.acm.org/doi/pdf/10.5555/3692070.3694025)]

**VTensor: Using Virtual Tensors to Build a Layout-oblivious AI Programming Framework**

Feng Yu, Jiacheng Zhao, Huimin Cui, Xiaobing Feng, Jingling Xue

*PACT '20: Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3410463.3414664)]

**ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**

Lu Ye, Ze Tao, Yong Huang, Yang Li

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)* [[pdf](https://aclanthology.org/2024.acl-long.623.pdf)]

**BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching**

Zhen Zheng, Xin Ji, Taosong Fang, Fanghao Zhou, Chuanjie Liu, Gang Peng

*arXiv preprint arXiv:2412.03594* [[pdf](https://arxiv.org/pdf/2412.03594.pdf)]



#### 2.4.3 Data Storage For RAG

**Caching of Retrieval Augmented Generation Model Trained with Dynamic Data and Dynamically Updating of Cache**

Mustafa Kadioglu, Paul C. Stojanovski, Sunil Karthik Kota

*Technical Disclosure Commons, 2024* [[pdf](https://www.tdcommons.org/dpubs_series/7154/)]

**Similarity Search in the Blink of an Eye with Compressed Indices**

Cecilia Aguerrebere, Ishwar Singh Bhati, Mark Hildebrand, Mariano Tepper, Theodore Willke

*Proceedings of the VLDB Endowment, Volume 16, Issue 11* [[pdf](https://doi.org/10.14778/3611479.3611537)]

**Empirical Evaluation of a Cloud-Based Graph Database: the Case of Neptune**
*Ghislain Auguste Atemezing. Knowledge Graphs and Semantic Web: Third Iberoamerican Conference and Second Indo-American Conference, 2021.*[[pdf](https://doi.org/10.1007/978-3-030-91305-2_3)]

**The Faiss Library**
*Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, Hervé Jégou. arXiv 2024.*[[pdf](https://doi.org/10.48550/arXiv.2401.08281)]

**Survey of Hallucination in Natural Language Generation**
*Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, Pascale Fung. ACM Computing Surveys, 2023.*[[pdf](https://doi.org/10.1145/3571730)]

**RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**

Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe Liu, Xin Jin

*arXiv preprint arXiv:2404.12457* [[pdf](https://arxiv.org/abs/2404.12457)]

**Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**
*Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen - tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela. NeurIPS 2020.*[[pdf](https://doi.org/10.48550/arXiv.2005.11401)]

**CacheGen: KV Cache Compression and Streaming for Fast Large Language Model Serving**

Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi Yao, Shan Lu, Ganesh Ananthanarayanan, Michael Maire, Henry Hoffmann, Ari Holtzman, Junchen Jiang

*ACM SIGCOMM '24: Proceedings of the ACM SIGCOMM 2024 Conference* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3651890.3672274)]

**TurboRAG: Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text**

Songshuo Lu, Hua Wang, Yutian Rong, Zhi Chen, Yaohua Tang

*arXiv preprint arXiv:2410.07590* [[pdf](https://arxiv.org/pdf/2410.07590.pdf)]

**Graph Databases Assessment: JanusGraph, Neo4j, and TigerGraph**
*Jéssica Monteiro, Filipe Sá, Jorge Bernardino. Perspectives and Trends in Education and Technology, 2023.*[[pdf](https://doi.org/10.1007/978-981-19-6585-2_58)]

**Survey of vector database management systems**
*James Jie Pan, Jianguo Wang, Guoliang Li. The VLDB Journal, 2024.*[[pdf](https://doi.org/10.1007/s00778-024-00864-x)]

**LeanVec: Searching Vectors Faster by Making Them Fit**

Mariano Tepper, Ishwar Singh Bhati, Cecilia Aguerrebere, Mark Hildebrand, Ted Willke

*arXiv:2312.16335 [cs.LG] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2312.16335)]

**GleanVec: Accelerating Vector Search with Minimalist Nonlinear Dimensionality Reduction**

Mariano Tepper, Ishwar Singh Bhati, Cecilia Aguerrebere, Ted Willke

*arXiv:2410.22347 [cs.IR] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2410.22347)]

**CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion**

Jiayi Yao, Hanchen Li, Yuhan Liu, Siddhant Ray, Yihua Cheng, Qizheng Zhang, Kuntai Du, Shan Lu, Junchen Jiang

*arXiv preprint arXiv:2405.16444* [[pdf](https://arxiv.org/abs/2405.16444)]



### 2.5 Data Serving for LLM

#### 2.5.1 Data Serving for Training

**NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks**

Jean-michel Attendu, Jean-philippe Corbeil

*Proceedings of The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP), 2023* [[pdf](https://aclanthology.org/2023.sustainlp-1.9.pdf)]

**Fewer Truncations Improve Language Modeling**

Hantian Ding, Zijian Wang, Giovanni Paolini, Varun Kumar, Anoop Deoras, Dan Roth, Stefano Soatto

*ICML 2024* [[pdf](https://doi.org/10.48550/arXiv.2404.10830)]

**How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition**

Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024* [[pdf](https://aclanthology.org/2024.acl-long.12.pdf)]

**BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning**

Mohsen Fayyaz, Ehsan Aghazadeh, Ali Modarressi, Mohammad Taher Pilehvar, Yadollah Yaghoobzadeh, Samira Ebrahimi Kahou

*ENLSP @ NeurIPS 2022* [[pdf](https://doi.org/10.48550/arXiv.2211.05610)]

**Automatic Pruning of Fine-tuning Datasets for Transformer-based Language Models**

Mohammadreza Tayaranian, Seyyed Hasan Mozafari, Brett H. Meyer, James J. Clark, Warren J. Gross

*Third Conference on Lifelong Learning Agents (CoLLAs 2024)* [[pdf](https://doi.org/10.48550/arXiv.2407.08887)]

**Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning**

Jisu Kim, Juhwan Lee

*arXiv:2405.07490 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2405.07490)]

**Efficient Sequence Packing without Cross-contamination: Accelerating Large Language Models without Impacting Performance**

Mario Michael Krell, Matej Kosec, Sergio P. Perez, Andrew Fitzgibbon

*arXiv:2107.02027 [cs.CL] (2021)* [[pdf](https://doi.org/10.48550/arXiv.2107.02027)]

**Bucket Pre-training is All You Need**

Hongtao Liu, Qiyao Peng, Qing Yang, Kai Liu, Hongyan Xu

*arXiv:2407.07495 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2407.07495)]

**Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory**

James L. McClelland, Bruce L. McNaughton, Randall C. O’Reilly

*Psychological Review, in press* [[pdf](https://cseweb.ucsd.edu/~gary/258/jay.pdf)]

**Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem**
M. McCloskey, N. J. Cohen

*Published 1989, Computer Science, Psychology, Psychology of Learning and Motivation* [[pdf](https://www.sciencedirect.com/science/article/abs/pii/S0079742108605368)]

**Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum**

Hadi Pouransari, Chun-Liang Li, Jen-Hao Rick Chang, Pavan Kumar Anasosalu Vasu, Cem Koc, Vaishaal Shankar, Oncel Tuzel

*NeurIPS 2024* [[pdf](https://doi.org/10.48550/arXiv.2405.13226)]

**In-context Pretraining: Language Modeling Beyond Document Boundaries**

Weijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou, Margaret Li, Gergely Szilvasy, Rich James, Xi Victoria Lin, Noah A. Smith, Luke Zettlemoyer, Scott Yih, Mike Lewis

*ICLR 2024* [[pdf](https://doi.org/10.48550/arXiv.2310.10638)]

**Structured Packing in LLM Training Improves Long Context Utilization**

Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, Yu Zhao, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś

*AAAI 2025* [[pdf](https://doi.org/10.48550/arXiv.2312.17296)]



#### 2.5.2 Data Serving for Inference

**Adapting Language Models to Compress Contexts**

Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen

*Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing* [[pdf](https://aclanthology.org/2023.emnlp-main.232.pdf)]

**LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models**

Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu

*Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing* [[pdf](https://aclanthology.org/2023.emnlp-main.825.pdf)]

**LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression**

Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu

*ACL 2024* [[pdf](https://aclanthology.org/2024.acl-long.91/)]

**Learning to Compress Prompts with Gist Tokens**

Jesse Mu, Xiang Lisa Li, Noah Goodman

*NeurIPS 2023* [[pdf](https://arxiv.org/abs/2304.08467)]

**LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression**

Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rühle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang

*Findings of the Association for Computational Linguistics: ACL 2024* [[pdf](https://aclanthology.org/2024.findings-acl.57.pdf)]



#### 2.5.3 Data Serving for RAG

**ASRank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval**

Abdelrahman Abdallah, Jamshid Mozafari, Bhawna Piryani, Adam Jatowt

*NAACL 2025* [[pdf](https://doi.org/10.48550/arXiv.2501.15245)]

**xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token**
Xin Cheng, Xun Wang, Xingxing Zhang, Tao Ge, Si-Qing Chen, Furu Wei, Huishuai Zhang, Dongyan Zhao

*NeurIPS 2024* [[pdf](https://doi.org/10.48550/arXiv.2405.13792)]

**From Local to Global: A Graph RAG Approach to Query-Focused Summarization**  
Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, Jonathan Larson  
*arXiv:2404.16130 [cs.CL]* 2024 [[pdf]](https://doi.org/10.48550/arXiv.2404.16130)

**ARAGOG: Advanced RAG Output Grading**

Matouš Eibich, Shivay Nagpal, Alexander Fred-Ojala

*arXiv:2404.01037 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2404.01037)]

**M3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation**
Jianlyu Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu

*Findings of the Association for Computational Linguistics: ACL 2024, pages 2318–2335* [[pdf](https://aclanthology.org/2024.findings-acl.137.pdf)]

**MiniRAG: Towards Extremely Simple Retrieval - Augmented Generation**  
Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang  
*arXiv:2501.06713 [cs.AI]* 2024 [[pdf]](https://doi.org/10.48550/arXiv.2501.06713)

**Retrieval-Augmented Generation for Large Language Models: A Survey**

Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang

*arXiv:2312.10997 [cs.CL]* [[pdf](https://arxiv.org/pdf/2312.10997.pdf)]

**LightRAG: Simple and Fast Retrieval - Augmented Generation**  
Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang  
*arXiv:2410.05779 [cs.IR]* 2024 [[pdf]](https://arxiv.org/abs/2410.05779)

**Familiarity-Aware Evidence Compression for Retrieval-Augmented Generation**
Dongwon Jung, Qin Liu, Tenghao Huang, Ben Zhou, Muhao Chen

*arXiv:2409.12468 [cs.CL]* [[pdf](https://doi.org/10.48550/arXiv.2409.12468)]

**Towards General Text Embeddings with Multi-stage Contrastive Learning**
Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang

*arXiv:2308.03281 [cs.CL]* [[pdf](https://arxiv.org/abs/2308.03281)]

**RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models**

Ronak Pradeep, Sahel Sharifymoghaddam, Jimmy Lin

*arXiv:2309.15088 [cs.IR] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2309.15088)]

**Grounding Language Model with Chunking-Free In-Context Retrieval**

Hongjin Qian, Zheng Liu, Kelong Mao, Yujia Zhou, Zhicheng Dou

*In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024, pp. 1298 - 1311.* [[pdf](https://aclanthology.org/2024.acl-long.71/)] 

**Learning Transferable Visual Models From Natural Language Supervision**
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 

*arxiv 2021.*[[pdf](https://arxiv.org/abs/2103.00020)]

**Context Embeddings for Efficient Answer Generation in RAG**
David Rau, Shuai Wang, Hervé Déjean, Stéphane Clinchant

*WSDM 2025* [[pdf](https://doi.org/10.48550/arXiv.2407.09252)]

**Compressing Long Context for Enhancing RAG with AMR-based Concept Distillation**
Kaize Shi, Xueyao Sun, Qing Li, Guandong Xu

*arXiv:2405.03085 [cs.CL]* [[pdf](https://doi.org/10.48550/arXiv.2405.03085)]

**RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation**
Fangyuan Xu, Weijia Shi, Eunsol Choi

*ICLR 2024* [[pdf](https://iclr.cc/virtual/2024/poster/17885)]

**Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation**

Zijie Zhong, Hanwen Liu, Xiaoya Cui, Xiaofan Zhang, Zengchang Qin

*COLING 2025* [[pdf](https://doi.org/10.48550/arXiv.2406.00456)]



## 3 LLM for Data Management

### 3.1 LLM for Data Exploration

#### 3.1.1 LLM for Data Cleaning

**GIDCL: A Graph-Enhanced Interpretable Data Cleaning Framework with Large Language Models**
Mengyi Yan, Yaoshu Wang, Yue Wang, Xiaoye Miao, Jianxin Li

*Proceedings of the ACM on Management of Data, Volume 2, Issue 6, Article No. 236, Pages 1-29* [[pdf](https://doi.org/10.1145/3698811)]



#### 3.1.2 LLM for Entity Matching

**Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration**
Meihao Fan, Xiaoyue Han, Ju Fan, Chengliang Chai, Nan Tang, Guoliang Li

*2024 IEEE 40th International Conference on Data Engineering (ICDE)* [[pdf](https://ieeexplore.ieee.org/document/10597751)]

**Entity Matching using Large Language Models**
Ralph Peeters, Aaron Steiner, Christian Bizer

*Proceedings of the 28th International Conference on Extending Database Technology (EDBT), 25th March-28th March, 2025* [[pdf](https://doi.org/10.48550/arXiv.2310.11244)]

**Unicorn: A Unified Multi-tasking Model for Supporting Matching Tasks in Data Integration**
Jianhong Tu, Ju Fan, Nan Tang, Peng Wang, Guoliang Li, Xiaoyong Du, Xiaofeng Jia, Song Gao

*Proceedings of the ACM on Management of Data, Volume 1, Issue 1, Article No. 84, Pages 1-26* [[pdf](https://doi.org/10.1145/3588938)]

**Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching**

Tianshu Wang, Xiaoyang Chen, Hongyu Lin, Xuanang Chen, Xianpei Han, Hao Wang, Zhenyu Zeng, Le Sun

*COLING 2025* [[pdf](https://doi.org/10.48550/arXiv.2405.16884)]

**KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs**

Yongqin Xu, Huan Li, Ke Chen, Lidan Shou

*arXiv:2410.12480 [cs.CL]* [[pdf](https://doi.org/10.48550/arXiv.2410.12480)]



#### 3.1.3 LLM for Schema Matching

**Magneto: Combining Small and Large Language Models for Schema Matching**

Yurong Liu, Eduardo Pena, Aecio Santos, Eden Wu, Juliana Freire

*arXiv:2412.08194 [cs.DB]* [[pdf](https://doi.org/10.48550/arXiv.2412.08194)]

**Schema Matching with Large Language Models: an Experimental Study**

Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

*TaDA24 (collocated with VLDB 2024)* [[pdf](https://doi.org/10.48550/arXiv.2407.11852)]



#### 3.1.4 LLM for Data Discovery

### 3.2 LLM for Data Analysis

#### 3.2.1 LLM for Structured Data Analysis

**Survey of Graph Database Models**

Renzo Angles, Claudio Gutierrez

*ACM Computing Surveys (CSUR), Volume 40, Issue 1, Article No. 1, Pages 1-39* [[pdf](https://doi.org/10.1145/1322432.1322433)]

**A Relational Model of Data for Large Shared Data Banks**

E. F. Codd

*Communications of the ACM, Volume 13, Issue 6, Pages 377-387* [[pdf](https://doi.org/10.1145/362384.362685)]



*3.2.1.1 Relational Data Analysis*

**TableMaster: A Recipe to Advance Table Understanding with Language Models**

Lang Cao

*arXiv:2501.19378 [cs.CL]* [[pdf](https://doi.org/10.48550/arXiv.2501.19378)]

**PaLM: Scaling Language Modeling with Pathways**
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, et al.

*The Journal of Machine Learning Research, Volume 24, Issue 1, Article No. 240, Pages 11324-11436[[pdf](https://dl.acm.org/doi/10.5555/3648699.3648939)]*

**Data Interpreter: An LLM Agent For Data Science**
Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Ceyao Zhang, Chenxing Wei, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, Lingyao Zhang, Min Yang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Xiangru Tang, Xiangtao Lu, Xiawu Zheng, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zhibin Gou, Zongze Xu, Chenglin Wu
*arXiv Preprint 2402.18679 [cs.AI]* [[pdf](https://arxiv.org/pdf/2402.18679.pdf)]

**Contextualized Data-Wrangling Code Generation in Computational Notebooks**  
Junjie Huang, Daya Guo, Chenglong Wang, Jiazhen Gu, Shuai Lu, Jeevana Priya Inala, Cong Yan, Jianfeng Gao, Nan Duan, Michael R. Lyu  

*arXiv:2409.13551 [cs.SE]* [[pdf](https://doi.org/10.48550/arXiv.2409.13551)]

**S3HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering**
Fangyu Lei, Xiang Li, Yifan Wei, Shizhu He, Yiming Huang, Jun Zhao, Kang Liu
*Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)* [[pdf](https://aclanthology.org/2023.acl-short.147/)]

**CodeS: Towards Building Open-source Language Models for Text-to-SQL**

Haoyang Li, Jing Zhang, Hanbing Liu, Ju Fan, Xiaokang Zhang, Jun Zhu, Renjie Wei, Hongyan Pan, Cuiping Li, Hong Chen

*Proceedings of the ACM on Management of Data, Volume 2, Issue 3, 2024* [[pdf](https://doi.org/10.1145/3654930)]

**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**

Zhishuai Li, Xiang Wang, Jingjing Zhao, Sun Yang, Guoqing Du, Xiaoru Hu, Bin Zhang, Yuxiao Ye, Ziyue Li, Rui Zhao, Hangyu Mao

*arXiv:2403.09732 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.09732)]

**Table-GPT: Table Fine-tuned GPT for Diverse Table Tasks**

Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, Haidong Zhang, Danielle Rifinski Fainman, Dongmei Zhang, Surajit Chaudhuri

*Proceedings of the ACM on Management of Data, Volume 2, Issue 3, 2024* [[pdf](https://doi.org/10.1145/3654979)]

**Improved Baselines with Visual Instruction Tuning**

Haotian Liu, Chunyuan Li, Yuheng Li, Yong Jae Lee

*2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)* [[pdf](https://ieeexplore.ieee.org/document/10655294)]

**CABINET: Content Relevance based Noise Reduction for Table Question Answering**

Sohan Patnaik, Heril Changwal, Milan Aggarwal, Sumit Bhatia, Yaman Kumar, Balaji Krishnamurthy

*ICLR 2024 (spotlight)* [[pdf](https://doi.org/10.48550/arXiv.2402.01155)]

**Qwen2.5 Technical Report**

An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu (additional authors not shown)

*arXiv:2412.15115 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2412.15115)]

**TableGPT2: A Large Multimodal Model with Tabular Data Integration**

Aofeng Su, Aowen Wang, Chao Ye, Chen Zhou, Ga Zhang, Gang Chen, Guangcheng Zhu, Haobo Wang, Haokai Xu, Hao Chen, Haoze Li, Haoxuan Lan, Jiaming Tian, Jing Yuan, Junbo Zhao, Junlin Zhou, Kaizhe Shou, Liangyu Zha, Lin Long, Liyao Li, Pengzuo Wu, Qi Zhang, Qingyi Huang, Saisai Yang, Tao Zhang, Wentao Ye, Wufang Zhu, Xiaomeng Hu, Xijun Gu, Xinjie Sun, Xiang Li, Yuhang Yang, Zhiqing Xiao

*arXiv:2411.02059 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2411.02059)]

**CHESS: Contextual Harnessing for Efficient SQL Synthesis**

Shayan Talaei, Mohammadreza Pourreza, Yu-Chen Chang, Azalia Mirhoseini, Amin Saberi

*arXiv:2405.16755 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2405.16755)]

**Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**

Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister

*ICLR 2024* [[pdf](https://doi.org/10.48550/arXiv.2401.04398)]

**Natural Language to Code Generation in Interactive Data Science Notebooks**

Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski, Oleksandr Polozov, Charles Sutton

*Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2023* [[pdf](https://aclanthology.org/2023.acl-long.9/)]

**FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis**

Chao Zhang, Yuren Mao, Yijiang Fan, Yu Mi, Yunjun Gao, Lu Chen, Dongfang Lou, Jinshu Lin

*SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data* [[pdf](https://doi.org/10.1145/3626246.3653375)]

**ReAcTable: Enhancing ReAct for Table Question Answering**

Yunjia Zhang, Jordan Henkel, Avrilia Floratou, Joyce Cahoon, Shaleen Deep, Jignesh M. Patel

*Proceedings of the VLDB Endowment, Volume 17, Issue 8, 2024* [[pdf](https://doi.org/10.14778/3659437.3659452)]

**TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy**

Weichao Zhao, Hao Feng, Qi Liu, Jingqun Tang, Shu Wei, Binghong Wu, Lei Liao, Yongjie Ye, Hao Liu, Wengang Zhou, Houqiang Li, Can Huang

*NeurIPS 2024* [[pdf](https://doi.org/10.48550/arXiv.2406.01326)]

**TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table QA by Content Planning and Execution-based Reasoning**

Yilun Zhao, Lyuhao Chen, Arman Cohan, Chen Zhao

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024* [[pdf](https://aclanthology.org/2024.acl-long.692/)]

**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena**

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica

*NeurIPS 2023 Datasets and Benchmarks Track* [[pdf](https://doi.org/10.48550/arXiv.2306.05685)]

**Multimodal Table Understanding**

Mingyu Zheng, Xinwei Feng, Qingyi Si, Qiaoqiao She, Zheng Lin, Wenbin Jiang, Weiping Wang

*ACL 2024 Main Conference* [[pdf](https://doi.org/10.48550/arXiv.2406.08100)]

**TAT-LLM: A Specialized Language Model for Discrete Reasoning over Financial Tabular and Textual Data**

Fengbin Zhu, Ziyang Liu, Fuli Feng, Chao Wang, Moxin Li, Tat Seng Chua

*ICAIF '24: Proceedings of the 5th ACM International Conference on AI in Finance* [[pdf](https://doi.org/10.1145/3677052.3698685)]



*3.2.1.2 Graph Data Analysis*

**A Comparison of Current Graph Database Models**

Renzo Angles

*ICDEW '12: Proceedings of the 2012 IEEE 28th International Conference on Data Engineering Workshops* [[pdf](https://doi.org/10.1109/ICDEW.2012.31)]

**Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments**

Sitao Cheng, Ziyuan Zhuang, Yong Xu, Fangkai Yang, Chaoyun Zhang, Xiaoting Qin, Xiang Huang, Ling Chen, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

*ACL 2024 Findings* [[pdf](https://doi.org/10.48550/arXiv.2403.08593)]

**Inductive representation learning on large graphs**

William L. Hamilton, Rex Ying, Jure Leskovec

*NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems* [[pdf](https://dl.acm.org/doi/10.5555/3294771.3294869)]

**StructGPT: A General Framework for Large Language Model to Reason over Structured Data**

Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, Ji-Rong Wen

*EMNLP 2023* [[pdf](https://doi.org/10.48550/arXiv.2305.09645)]

**UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph**

Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Ji-Rong Wen

*ICLR 2023* [[pdf](https://doi.org/10.48550/arXiv.2212.00959)]

**Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**

Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang

*arXiv:2412.12456 [cs.LG] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2412.12456)]

**FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering**

Zhenyu Li, Sunqi Fan, Yu Gu, Xiuxing Li, Zhichao Duan, Bowen Dong, Ning Liu, Jianyong Wang

*AAAI 2024 (Oral)* [[pdf](https://doi.org/10.48550/arXiv.2308.12060)]

**NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language**

Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian

*arXiv:2412.10434 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2412.10434)]

**Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey**

Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Yue Wang, Zun Wang, Tao Qin, Rui Yan

*arXiv:2403.01528 [cs.CL] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.01528)]

**Semi-Supervised Classification with Graph Convolutional Networks**

Thomas N. Kipf, Max Welling

*ICLR 2017* [[pdf](https://doi.org/10.48550/arXiv.1609.02907)]

**Direct Preference Optimization: Your Language Model is Secretly a Reward Model**

Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, Chelsea Finn

*NeurIPS 2023* [[pdf](https://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html)]

**GraphGPT: Graph Instruction Tuning for Large Language Models**

Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, Chao Huang

*SIGIR 2024* [[pdf](https://doi.org/10.48550/arXiv.2310.13023)]

**InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment**

Jianing Wang, Junda Wu, Yupeng Hou, Yao Liu, Ming Gao, Julian McAuley

*Findings of the Association for Computational Linguistics: ACL 2024* [[pdf](https://aclanthology.org/2024.findings-acl.801/)]

**Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models**

Guanming Xiong, Junwei Bao, Wen Zhao

*Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024* [[pdf](https://aclanthology.org/2024.acl-long.569/)]

**Language is All a Graph Needs**

Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang

*Findings of the Association for Computational Linguistics: EACL 2024* [[pdf](https://aclanthology.org/2024.findings-eacl.132/)]

**Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering**

Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, Hong Chen

*Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022* [[pdf](https://aclanthology.org/2022.acl-long.396/)]

**R3-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL**

Yuhang Zhou, Yu He, Siyu Tian, Yuchen Ni, Zhangyue Yin, Xiang Liu, Chuanjun Ji, Sen Liu, Xipeng Qiu, Guangnan Ye, Hongfeng Chai

*Findings of the Association for Computational Linguistics: EMNLP 2024* [[pdf](https://aclanthology.org/2024.findings-emnlp.800/)]



#### 3.2.2 LLM for Semi-Structured Data Analysis

**Querying Semi-Structured Data**

Serge Abiteboul

*ICDT '97: Proceedings of the 6th International Conference on Database Theory* [[pdf](https://dl.acm.org/doi/10.5555/645502.656103)]



*3.2.2.1 Markup Language*
*3.2.2.2 Semi-Structured Tables*

**TempTabQA: Temporal Question Answering for Semi-Structured Tables**

Vivek Gupta, Pranshu Kandoi, Mahek Bhavesh Vora, Shuo Zhang, Yujie He, Ridho Reinanda, Vivek Srikumar

*EMNLP 2023 (Main Conference)* [[pdf](https://doi.org/10.48550/arXiv.2311.08002)]

**MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for Table Reasoning**

Zheng Li, Yang Du, Mao Zheng, Mingyang Song

*COLING 2025* [[pdf](https://doi.org/10.48550/arXiv.2412.11711)]

**SpreadsheetBench: Towards Challenging Real World Spreadsheet Manipulation**

Zeyao Ma, Bohan Zhang, Jing Zhang, Jifan Yu, Xiaokang Zhang, Xiaohan Zhang, Sijia Luo, Xi Wang, Jie Tang

*NeurIPS 2024 (Spotlight)* [[pdf](https://doi.org/10.48550/arXiv.2406.14991)]



#### 3.2.3 LLM for Unstructured Data Analysis

*3.2.3.1 Documents*

**DocFormerv2: Local Features for Document Understanding**

Srikar Appalaraju, Peng Tang, Qi Dong, Nishant Sankaran, Yichu Zhou, R. Manmatha

*AAAI 2024* [[pdf](https://doi.org/10.1609/aaai.v38i2.27828)]

**DUBLIN: Visual Document Understanding By Language-Image Network**

Kriti Aggarwal, Aditi Khandelwal, Kumar Tanmay, Owais Khan Mohammed, Qiang Liu, Monojit Choudhury, Hardik Chauhan, Subhojit Som, Vishrav Chaudhary, Saurabh Tiwary

*Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track* [[pdf](https://aclanthology.org/2023.emnlp-industry.65/)]

**An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**

Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby

*arXiv:2010.11929 [cs.CV] (2020)* [[pdf](https://arxiv.org/abs/2010.11929)]

**DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding**

Hao Feng, Qi Liu, Hao Liu, Jingqun Tang, Wengang Zhou, Houqiang Li, Can Huang

*Science China Information Sciences (SCIS)* [[pdf](https://doi.org/10.48550/arXiv.2311.11810)]

**Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**

Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova

*ICML 2023* [[pdf](https://doi.org/10.48550/arXiv.2210.03347)]

**Focus Anywhere for Fine-grained Multi-page Document Understanding**
*Chenglong Liu, Haoran Wei, Jinyue Chen, Lingyu Kong, Zheng Ge, Zining Zhu, Liang Zhao, Jianjian Sun, Chunrui Han, Xiangyu Zhang. arxiv 2024.*[[pdf](https://arxiv.org/abs/2405.14295)]

**mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding**

Anwen Hu, Haiyang Xu, Jiabo Ye, Ming Yan, Liang Zhang, Bo Zhang, Ji Zhang, Qin Jin, Fei Huang, Jingren Zhou

*Findings of the Association for Computational Linguistics: EMNLP 2024* [[pdf](https://aclanthology.org/2024.findings-emnlp.175/)]

**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu

*The Journal of Machine Learning Research, Volume 21, Issue 1* [[pdf](https://dl.acm.org/doi/10.5555/3455716.3455856)]

**Unifying Vision, Text, and Layout for Universal Document Processing** 

Zineng Tang, Ziyi Yang, Guoxin Wang, Yuwei Fang, Yang Liu, Chenguang Zhu, Michael Zeng, Cha Zhang, Mohit Bansal *arXiv:2212.02623 [cs.CV].* [[pdf](https://arxiv.org/abs/2212.02623v3)] 

**The JPEG Still Picture Compression Standard**

Gregory K. Wallace

*Communications of the ACM, Volume 34, Issue 4* [[pdf](https://doi.org/10.1145/103085.103089)]

**General OCR Theory: Towards OCR - 2.0 via a Unified End - to - end Model** 

Haoran Wei, Chenglong Liu, Jinyue Chen, Jia Wang, Lingyu Kong, Yanming Xu, Zheng Ge, Liang Zhao, Jianjian Sun, Yuang Peng, Chunrui Han, Xiangyu Zhang *arXiv:2409.01704 [cs.CV].* [[pdf](https://arxiv.org/abs/2409.01704v1)] 



*3.2.3.2 Program Language Analysis*

**Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)**

Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, Earl Barr

*ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering* [[pdf](https://doi.org/10.1145/3597503.3639183)]

**CodeBERT: A Pre-Trained Model for Programming and Natural Languages**

Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou

*Findings of EMNLP 2020* [[pdf](https://doi.org/10.48550/arXiv.2002.08155)]

**CoCoMIC: Code Completion by Jointly Modeling In-file and Cross-file Context**

Yangruibo Ding, Zijian Wang, Wasi Ahmad, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth, Bing Xiang

*Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)* [[pdf](https://aclanthology.org/2024.lrec-main.305/)]

**Code Structure–Guided Transformer for Source Code Summarization**

Shuzheng Gao, Cuiyun Gao, Yulan He, Jichuan Zeng, Lunyiu Nie, Xin Xia, Michael Lyu

*ACM Transactions on Software Engineering and Methodology, Volume 32, Issue 1* [[pdf](https://doi.org/10.1145/3522674)]

**Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning**

Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, Xiangke Liao

*ICSE '24: Proceedings of the 46th IEEE/ACM International Conference on Software Engineering* [[pdf](https://doi.org/10.1145/3597503.3608134)]

**Software Vulnerability Detection with GPT and In-Context Learning**

Zhihong Liu, Qing Liao, Wenchao Gu, Cuiyun Gao

*2023 8th International Conference on Data Science in Cyberspace (DSC)* [[pdf](https://ieeexplore.ieee.org/abstract/document/10381286)]

**Pre-training by Predicting Program Dependencies for Vulnerability Analysis Tasks**

Zhongxin Liu, Zhijie Tang, Junwei Zhang, Xin Xia, Xiaohu Yang

*ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering* [[pdf](https://doi.org/10.1145/3597503.3639142)]

**SCLA: Automated Smart Contract Summarization via LLMs and Semantic Augmentation**

Yingjie Mao, Xiaoqi Li, Wenkai Li, Xin Wang, Lei Xie

*arXiv:2402.04863 [cs.SE] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2402.04863)]

**The Probabilistic Relevance Framework: BM25 and Beyond**

Stephen Robertson, Hugo Zaragoza

*Foundations and Trends in Information Retrieval, Volume 3, Issue 4* [[pdf](https://dl.acm.org/doi/10.1561/1500000019)]

**RepoFusion: Training Code Models to Understand Your Repository**

Disha Shrivastava, Denis Kocetkov, Harm de Vries, Dzmitry Bahdanau, Torsten Scholak

*arXiv:2306.10998 [cs.LG] (2023)* [[pdf](https://doi.org/10.48550/arXiv.2306.10998)]

**Improving Code Summarization With Tree Transformer Enhanced by Position-Related Syntax Complement**

Jie Song, Zexin Zhang, Zirui Tang, Shi Feng, Yu Gu

*IEEE Transactions on Artificial Intelligence, Volume 5, Issue 9, September 2024* [[pdf](https://ieeexplore.ieee.org/document/10510878/metrics#metrics)]

**Repoformer: Selective Retrieval for Repository-Level Code Completion**

Di Wu, Wasi Uddin Ahmad, Dejiao Zhang, Murali Krishna Ramanathan, Xiaofei Ma

*ICML 2024* [[pdf](https://doi.org/10.48550/arXiv.2403.10059)]

**Vulnerability Detection by Learning From Syntax-Based Execution Paths of Code**

Junwei Zhang, Zhongxin Liu, Xing Hu, Xin Xia, Shanping Li

*IEEE Transactions on Software Engineering, Volume 49, Issue 8, August 2023* [[pdf](https://ieeexplore.ieee.org/document/10153647)]

**Large Language Model for Vulnerability Detection: Emerging Results and Future Directions**

Xin Zhou, Ting Zhang, David Lo

*ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results* [[pdf](https://doi.org/10.1145/3639476.3639762)]



### 3.3 LLM for Data System Optimization

#### 3.3.1 LLM for Configuration Tuning

**Automatic Database Management System Tuning Through Large-scale Machine Learning**

Dana Van Aken, Andrew Pavlo, Geoffrey J. Gordon, Bohan Zhang

*SIGMOD '17: Proceedings of the 2017 ACM International Conference on Management of Data* [[pdf](https://doi.org/10.1145/3035918.3064029)]

**LATuner: An LLM-Enhanced Database Tuning System Based on Adaptive Surrogate Model**

Chongjiong Fan, Zhicheng Pan, Wenwen Sun, Chengcheng Yang, Wei-Neng Chen

*ECML PKDD 2024: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases* [[pdf](https://doi.org/10.1007/978-3-031-70362-1_22)]

**λ-Tune: Harnessing Large Language Models for Automated Database System Tuning**

Victor Giannankouris, Immanuel Trummer

*SIGMOD 2025* [[pdf](https://doi.org/10.48550/arXiv.2411.03500)]

**E2ETune: End-to-End Knob Tuning via Fine-tuned Generative Language Model**

Xinmei Huang, Haoyang Li, Jing Zhang, Xinxin Zhao, Zhiming Yao, Yiyan Li, Tieying Zhang, Jianjun Chen, Hong Chen, Cuiping Li

*VLDB 2025* [[pdf](https://doi.org/10.48550/arXiv.2404.11581)]

**GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization**

Jiale Lao, Yibo Wang, Yufei Li, Jianping Wang, Yunjia Zhang, Zhiyuan Cheng, Wanghu Chen, Mingjie Tang, Jianguo Wang

*Proceedings of the VLDB Endowment, Volume 17, Issue 8* [[pdf](https://doi.org/10.14778/3659437.3659449)]

**Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation**

Yiyan Li, Haoyang Li, Zhao Pu, Jing Zhang, Xinyi Zhang, Tao Ji, Luming Sun, Cuiping Li, Hong Chen

*arXiv:2408.02213 [cs.DB] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2408.02213)]

**DB-BERT: A Database Tuning Tool that "Reads the Manual"**

Immanuel Trummer

*SIGMOD '22: Proceedings of the 2022 International Conference on Management of Data* [[pdf](https://doi.org/10.1145/3514221.3517843)]

**Breaking It Down: An In-Depth Study of Index Advisors**

Wei Zhou, Chen Lin, Xuanhe Zhou, Guoliang Li

*Proceedings of the VLDB Endowment, Volume 17, Issue 10* [[pdf](https://doi.org/10.14778/3675034.3675035)]

**DB-GPT: Large Language Model Meets Database**

Xuanhe Zhou, Zhaoyan Sun, Guoliang Li

*Data Science and Engineering, Volume 9, pages 102–111, 2024* [[pdf](https://link.springer.com/article/10.1007/s41019-023-00235-6)]



#### 3.3.2 LLM for Query Optimization

**The Unreasonable Effectiveness of LLMs for Query Optimization**

Peter Akioyamen, Zixuan Yi, Ryan Marcus

*Machine Learning for Systems Workshop at NeurIPS 2024* [[pdf](https://doi.org/10.48550/arXiv.2411.02862)]

**Can Large Language Models Be Query Optimizer for Relational Databases?**

Jie Tan, Kangfei Zhao, Rui Li, Jeffrey Xu Yu, Chengzhi Piao, Hong Cheng, Helen Meng, Deli Zhao, Yu Rong

*arXiv:2502.05562 [cs.DB] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.05562)]

**LLM-R2: A Large Language Model Enhanced Rule-Based Rewrite System for Boosting Query Efficiency**

Zhaodonghui Li, Haitao Yuan, Huiming Wang, Gao Cong, Lidong Bing

*Proceedings of the VLDB Endowment, Volume 18, Issue 1* [[pdf](https://doi.org/10.14778/3696435.3696440)]

**Query Rewriting via Large Language Models**

Jie Liu, Barzan Mozafari

*arXiv:2403.09060 [cs.DB] (2024)* [[pdf](https://doi.org/10.48550/arXiv.2403.09060)]

**Query Rewriting via LLMs**

Sriram Dharwada, Himanshu Devrani, Jayant Haritsa, Harish Doraiswamy

*arXiv:2502.12918 [cs.DB] (2025)* [[pdf](https://doi.org/10.48550/arXiv.2502.12918)]

**R-Bot: An LLM-based Query Rewrite System**

Zhaoyan Sun, Xuanhe Zhou, Guoliang Li

*arXiv preprint arXiv:2412.01661* [[pdf](https://arxiv.org/abs/2412.01661)]

**DB-GPT: Large Language Model Meets Database**

Xuanhe Zhou, Zhaoyan Sun, Guoliang Li

*Data Science and Engineering, Volume 9, pages 102–111, 2024* [[pdf](https://link.springer.com/article/10.1007/s41019-023-00235-6)]



#### 3.3.3 LLM for Anomaly Diagnosis

**DBG-PT: A Large Language Model Assisted Query Performance Regression Debugger**

Victor Giannakouris, Immanuel Trummer

*Proceedings of the VLDB Endowment, Volume 17, Issue 12* [[pdf](https://doi.org/10.14778/3685800.3685869)]

**Panda: Performance Debugging for Databases using LLM Agents**  
Vikramank Singh, Kapil Eknath Vaidya, Vinayshekhar Bannihatti Kumar, Sopan Khosla, Balakrishnan Narayanaswamy, Rashmi Gangadharaiah, Tim Kraska  
*CIDR 2024* [[pdf](https://www.cidrdb.org/cidr2024/papers/p6-singh.pdf)]

**Query Performance Explanation through Large Language Model for HTAP Systems**  
Haibo Xiu, Li Zhang, Tieying Zhang, Jun Yang, Jianjun Chen  
*arXiv:2412.01709* [[pdf](https://doi.org/10.48550/arXiv.2412.01709)]

**LLM As DBA**  
Xuanhe Zhou, Guoliang Li, Zhiyuan Liu  
*arXiv:2308.05481* [[pdf](https://doi.org/10.48550/arXiv.2308.05481)]

**D-Bot: Database Diagnosis System using Large Language Models**  
Xuanhe Zhou, Guoliang Li, Zhaoyan Sun, Zhiyuan Liu, Weize Chen, Jianming Wu, Jiesi Liu, Ruohang Feng, Guoyang Zeng  
*Proceedings of the VLDB Endowment, Volume 17, Issue 10, Pages 2514 - 2527* [[pdf](https://doi.org/10.14778/3675034.3675043)]
